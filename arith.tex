\section{Syntax, Semantics, \& Machines for Arithmetic}

  \subsection{Modelling Syntax with Inductive Sets}

  The \emph{syntax} of a programming language is a set of rules for the
    arrangement of words and phrases to create well-formed sentences in
  the language.  In other words, it is the grammar of programs.  Syntax
    comes in two forms: \emph{concrete syntax} describes the way programs
	       actually look at the level of braces, semicolons, whitespace, etc.,
while \emph{abstract syntax} describes the structure of programs
without worrying over the superficial details of concrete syntax.
Concrete syntax, while the stuff of frenzied fervor, is actually not
all that significant for formally reasoning about programming
languages so we focus exclusively on abstract syntax.

Programs generally have a tree-like structure of nesting phrases and
expressions, so defining the abstract syntax of a language is no more
complicated than defining an inductive set.
%
As a case study, let's look at a very simple programming language, the
language of arithmetic expressions.  To keep things as simple as
possible, the language will include integers, a couple binary
operators like multiplication and addition, a unary operator for
successor and predecessor.

Here is an inductive mathematical definition of the set
$\Arith$.  It is the smallest set satisfying the following
constraints:

\begin{align}
i \in \mathbb{Z} \Rightarrow i \in \Arith\\
e \in \Arith \Rightarrow \Pred(e) \in \Arith\\
e \in \Arith \Rightarrow \Succ(e) \in \Arith\\
e_1 \in \Arith \wedge e_2 \in \Arith \Rightarrow \Plus(e_1,e_2) \in \Arith\\
e_1 \in \Arith \wedge e_2 \in \Arith \Rightarrow \Mult(e_1,e_2) \in \Arith
\end{align}


Like any inductive definition, this can be viewed simultaneously as a
recipe for \emph{constructing} members of the set $\Arith$ and as a
procedure for \emph{checking} if a value is a member of the set $\Arith$.

Interpreted as a recipe, you can see that every integer is an
$\Arith$ program; so $5$ is an $\Arith$ program by
(1).  Since $5$ is an $\Arith$ program, $\Pred(5)$ is
an $\Arith$ program by (2).  And therefore
$\Mult(\Pred(5),5)$ is an $\Arith$ program by
(5).  The recipe lets us build up bigger and bigger expressions from
other expressions.

Interpreted as a checking procedure, we can answer the question ``is
$\Plus(4,\Succ(2))$ an $\Arith$ program?''  It
is, according to (4), if both $4$ and $\Succ(2)$ are
$\Arith$ programs.  Since $4$ is an integer, it is an
$\Arith$ program; by (3), $\Succ(2)$ is an
$\Arith$ program if $2$ is an $\Arith$ program, which
of course it is, by (1).

An alternative notation for defining exactly the same set
$\Arith$ is to use a BNF grammar:

\[
\begin{array}{lrcll}
\mathbb{Z}
               & \mint & ::= & \dots\ |\ -1\ |\ 0\ |\ 1\ |\ \dots\\
 \Arith
               & e & ::= & i \\ % & \text{where }i\in\mathbb{Z}\\
               &   & |   & \Pred(e)\\
               &   & |   & \Succ(e)\\
               &   & |   & \Plus(e,e)\\
               &   & |   & \Mult(e,e)
\end{array}
\]

In both of these definitions, the occurrences of ``$\mint$'' and
``$\mexp$'' are occurrences of \deftech{meta-variables}---they are
variables in the language describing the programming language (in this
case $\Arith$).  The describing language itself (in this case math,
but often it is another programming language) is called the
\deftech{meta-language}, while the described language ($\Arith$) is
called the \deftech{object-language}.  By convention, the name of a
meta-variable signals the set of values it ranges over.  So for
example a meta-variable $\mint$ may refer to $5$ or $17$, but never
$\Succ(3)$.

Yet another notation for defining exactly the same set is to use
inference rules, which is a two-dimensional notation for writing
implications.  The general form of an \deftech{inference rule} is:
\begin{mathpar}
\inferrule{H_1 \\ H_2 \\ \dots \\ H_n }{C}
\end{mathpar}
Here $H_1$ through $H_n$ are hypotheses and $C$ is the conclusion.
The inference rule states that if $H_1$ through $H_n$ are true, then
conclusion must be true as well.  In other words, the inference rule
is just a notation for $H_1 \wedge H_2 \wedge \dots \wedge H_n
\Rightarrow C$.  With that in mind, it is straightforward to
transliterate the first formulation of $\Arith$ into a set of
inference rules:

\begin{mathpar}
  \inferrule*[Right=(1)]{i \in \mathbb{Z}}
             {i \in \Arith}

  \inferrule*[Right=(2)]{e \in \Arith}
             {\Pred(e) \in \Arith}

  \inferrule*[Right=(3)]{e \in \Arith}
             {\Succ(e) \in \Arith}

  \inferrule*[Right=(4)]{e_1 \in \Arith \\ e_2 \in \Arith}
             {\Plus(e_1,e_2) \in \Arith}

  \inferrule*[Right=(5)]{e_1 \in \Arith \\ e_2 \in \Arith}
             {\Mult(e_1,e_2) \in \Arith}
\end{mathpar}

This set of inference rules establishes a very simple \emph{proof
  system} for constructing proofs that an expression is in the set
$\Arith$.  A proof is simply a tree constructed following the
inference rules above.  As an example, here is a proof that
$\Plus(4,\Succ(2)) \in \Arith$.

\begin{mathpar}
\inferrule*
    { \inferrule*
      {4 \in \mathbb{Z}}
      {4 \in \Arith}
      \\
      \inferrule*
      {\inferrule*
        {2 \in \mathbb{Z}}
        {2 \in \Arith}}
      {\Succ(2) \in \Arith}}
    {\Plus(4,\Succ(2)) \in \Arith}
\end{mathpar}

It's easy to express any BNF grammar as an inductively defined set,
which in turn is easy to express as a set of inference rules.  But not
all inductive definitions or inference rules can be expressed as
grammars.  Consequently, syntax is often defined using BNF, while more
sophisticated relations are defined using inference rules.

\subsection{Modelling Syntax with Data}

Modelling programs with mathematics is a powerful idea that predates
computers, but it's arguably more useful to model programs with
programs.  In other words, we can write programs that operate over
data representations of programs.  From this perspective, the abstract
syntax of a programming language is just an inductive data type
definition.

Here is the data type definition for $\Arith$ that corresponds to the
earlier mathematical definition\footnote{Already a lie has crept in:
  OCaml's \syntax{int} is not the same as $\mathbb{Z}$.  We're going
  to ignore this discrepancy for the time being.  The problem could be
  resolved by using a big integer library, at the cost of some
  notational overhead in our examples.}, written in the OCaml
language:
%
\begin{verbatim}
   type arith = Int of int
              | Pred of arith
              | Succ of arith
              | Plus of arith * arith
              | Mult of arith * arith
\end{verbatim}
The only difference, which is inconsequential, is that OCaml, unlike
math, requires unions to be formed by disjoint types, so integers must
be ``tagged'' with the \syntax{Int} constructor to make them distinct
from integers.

We can rely on the type system of OCaml to verify when a value is a
member of the $\Arith$ set:
\begin{verbatim}
   # Plus (Int 4, Succ (Int 2));;
   - : arith = Plus (Int 4, Succ (Int 2))
\end{verbatim}


\subsection{Natural Semantics}
\label{sec:natural}


Perhaps the simplest semantics we can give arithmetic expressions is
to define a relation between an expression and the integer value it
simplifies to according to the usual rules of arithmetic.

To do this, we define a binary relation $\Downarrow\; \subseteq
\Arith \times \mathbb{Z}$.  When an expression $e$ is related
to an integer $i$, it means $e$ \emph{evaluates} to $i$.  Following
the usual convention, we write $e \Downarrow i$ to mean $(e,i) \in\;
\Downarrow$ (it's much easier to read $3 < 4$ instead of $(3,4) \in\;
<$, right?).

Just as we defined the set of $\Arith$ programs inductively,
we can define the evaluation relation $\Downarrow$ inductively as
well.

\begin{mathpar}
\inferrule{\ }
          {\mint \Downarrow \mint}

\inferrule{\mexp \Downarrow \mint}
          {\Pred(\mexp) \Downarrow \mint-1}

\inferrule{\mexp \Downarrow \mint}
          {\Succ(\mexp) \Downarrow \mint+1}

\inferrule{\mexp_1 \Downarrow i\\ \mexp_2 \Downarrow \moint}
          {\Plus(\mexp_1,\mexp_2) \Downarrow \mint+\moint}

\inferrule{\mexp_1 \Downarrow \mint\\ \mexp_2 \Downarrow \moint}
          {\Mult(\mexp_1,\mexp_2) \Downarrow \mint\cdot \moint}
\end{mathpar}


\paragraph{Note on notation:}
%
To be truly pedantic, we should add hypotheses to each of the inference
rules that state $e \in \Arith$ and $i \in \mathbb{Z}$ and so
on.  The convention that you'll frequently see, and which is used in
these notes, is that certain meta-variables range only over a
restricted set of values.  So if you see the meta-variable ``$e$'', you
can reasonably read it as $e$ such that $e \in \Arith$.  If
you see $e$ being used as something that is not an arithmetic
expression, then it's a mistake.  Likewise, $i$ and $j$ range only
over integers.


The simplest $\Arith$ expression is an integer, which cannot
be simplified further, so an integer evaluates to itself as shown in
the leftmost rule.  If an expression $e$ evaluates to an integer $i$,
then $\Succ(e)$ evaluates to $i+1$ as shown in the second
rule.  The remaining rules are similar.

The proof that an expression evaluates to some integer can be given as a
proof tree using these inference rules.  For example, here is the
proof that $\Plus(4,\Succ(2)) \Downarrow 7$.

\begin{mathpar}
\inferrule{\inferrule*{\ }
                      {4 \Downarrow 4}
                      \\
           \inferrule*{\inferrule*{\ }
                                  {2 \Downarrow 2}}
                      {\Succ(2) \Downarrow 3}}
          {\Plus(4,\Succ(2)) \Downarrow 7}
\end{mathpar}

When reading these inference rules, it's important to notice that the
right hand side of the evaluation relation is a mathematical
expression that denotes an integer; not a piece of syntax.  As the
previous example shows, $\Plus(4,\Succ(2))$ evaluates to $7$; not a
representation of the expression ``4+(2+1)''.  If it helps to see
this, a completely equivalent formulation of, for example, the $\Plus$
rule that stresses evaluation produces a single integer is:
\begin{mathpar}
\inferrule{\mexp_1 \Downarrow \mint \\ \mexp_2 \Downarrow j \\ k = i+j}
{\Plus(\mexp_1,\mexp_2) \Downarrow k}
\end{mathpar}


Evaluation is defined as a relation, but it is actually a special case
of a relation: it is a function.  Can you convince yourself of this?
That is, can you prove that if $e \Downarrow i$ and $e \Downarrow j$,
then $i=j$?  Assuming you can, that means we can write the
$\Downarrow$ function as a function in a programming language such as
OCaml.  It naturally is a recursive function over the data type of
syntax:
\begin{verbatim}
   let rec eval (e : arith) : int =
       match e with
         Int i -> i
       | Pred e -> (eval e) - 1
       | Succ e -> (eval e) + 1
       | Plus (e1, e2) -> (eval e1) + (eval e2)
       | Mult (e1, e2) -> (eval e1) * (eval e2)
\end{verbatim}

The evaluator can be used as a calculator for arithmetic expressions:
\begin{verbatim}
   # eval (Plus (Int 4, Succ (Int 2)));;
   - : int = 7
\end{verbatim}

The above semantics are called a ``\deftech{big-step}'' or ``\deftech{natural}''
semantics.  It has a simple correspondence with a structurally
recursive functional program.
% It has the nice property that proofs about program evaluation are
% compositional.
The meaning of a program is given by the irreducible value it
produces, so the semantics tells you \emph{what} a program evaluates
to.  If the ``what'' is all you are interested in, then this semantics
is adequate.

This brings up several questions.  What is a semantics for?  Why would
one semantics be preferred over another?  What other kind of semantics
could there possibly be?

\subsection{Reduction Semantics}

A semantics is useful for establishing properties of programs.  There
are all kinds of properties of programs, so there are all kinds of
semantics of programs; just like math or logic, there is no ``one true
semantics.''  The program properties of interest depend on what you
are trying to accomplish.  Are you trying to write a correct
interpreter?  The natural semantics is probably what you need since it
tells you what value the interpreter should produce.  Are you trying
to prove upper bounds on the cost of running some programs?  The
natural semantics won't work because it doesn't say \emph{anything}
about cost.  Ditto if you want to prove a program can run forever
without using all available memory.  So a semantics should be tailored
to properties of interest.

With that in mind, let's investigate a semantics that informs us of each
of the steps a computation goes through toward reaching a value.  This
is useful for determining, for example, if two programs reach the same
intermediate state, or in which order are operations performed during a
computation.  In other words, such a semantics would tell us more
about \emph{how} a program evaluates.

Fundamentally, we do this like before: by specifying relations on
syntax.  But instead of defining a ``evaluates to'' relation, we
define a ``steps to'' relation $\areducename$ that captures the basic
laws of arithmetic reduction.  The new relation does not relate
expressions to integers, but instead relates expressions to
expressions, i.e.~$\areducename \subseteq \Arith \times \Arith$.  The
meaning of related expressions $e_1$ and $e_2$ is that $e_1$ reduces
in one step to $e_2$.

\begin{mathpar}
\inferrule*{\ }
          {\areduce{\Pred(\mint)}{\mint-1}}

\inferrule*{\ }
          {\areduce{\Succ(\mint)}{\mint+1}}

\inferrule*{\ }
          {\areduce{\Plus(\mint,\moint)}{\mint+\moint}}

\inferrule*{\ }
          {\areduce{\Mult(\mint,\moint)}{\mint\cdot\moint}}

\end{mathpar}

These axioms\footnote{An axiom is just a inference rule with no
  hypotheses.} reflect the basic facts of reduction in arithmetic, but
they're still not enough to capture computation, since for example
$\Plus(4,\Succ(2))$ doesn't step to anything.  The
reason is that our axioms only apply when the arguments to operators
are integers, which is not the case here.  It is true that
$\Succ(2)$ steps to $3$, but none of the rules allows us to
evaluate inside of a nested expression.



Let's define another relation , $\step\; \subseteq \Arith \times
\Arith$, that allows steps within nested expressions.
%
For the language of $\Arith$ this amounts to taking the
\deftech{compatible closure} of $\reduce$ over the grammar of
expressions.  The compatible closure of a relation $\mathbf{r}$ over
some grammar $g$ derives a new relation $\mathbf{r}'$ that allows
$\mathbf{r}$ to be distributed through non-terminals in $g$.  Writing
this out explicitly for the case of $\reduce$ and $e$ is the following:

\begin{mathpar}
\inferrule*
    {e \reduce e'}
    {e \step e'}

\inferrule*
    {e \step e'}
    {\Pred(e) \step \Pred(e')}

\inferrule*
    {e \step e'}
    {\Succ(e) \step \Succ(e')}

\inferrule*
    {e_1 \step e_1'}
    {\Plus(e_1,e_2) \step \Plus(e_1',e_2)}

\inferrule*
    {e_2 \step e_2'}
    {\Plus(e_1,e_2) \step \Plus(e_1,e_2')}

\inferrule*
    {e_1 \step e_1'}
    {\Mult(e_1,e_2) \step \Mult(e_1',e_2)}

\inferrule*
    {e_2 \step e_2'}
    {\Mult(e_1,e_2) \step \Mult(e_1,e_2')}

\end{mathpar}
%
Using $\step$, we can see that $\Plus(4,\Succ(2))
\step \Plus(4,3)$ and $\Plus(4,3) \step 7$.
%
Evaluation of a program can be viewed a series of related expressions
arriving at a final answer.

If we'd like to capture the notion of ``$e$ steps to $e'$ in any
number of steps,'' we can define yet another relation, $\multistep\;
\subseteq \Arith\times\Arith$, as the reflexive, transitive closure of
$\step$.  The \deftech{reflexive closure} of a relation $\mathbf{r}
\subseteq X \times X$ is a relation $\mathbf{r}' \subseteq X \times X$
such that $x\in X \Rightarrow x \mathop{\mathbf{r}'} x$ and $x_1 \in X
\wedge x_2 \in X \wedge x_1 \mathop{\mathbf{r}} x_2 \Rightarrow x_1
\mathop{\mathbf{r}'} x_2$.  In other words, the reflexive closure of
$\mathbf{r}$ relates every thing in $\mathbf{r}$ plus it relates
everything to itself.  The reflexive closure of $\step$ captures the
notion of ``steps in zero or one step.''  The \deftech{transitive
  closure} of a relation $\mrel \subseteq X \times X$ is a relation
$\morel \subseteq X \times X$ such that $x_1 \mrel x_2 \Rightarrow x_1
\morel x_2$ and $x_1 \morel x_2 \wedge x_2 \morel x_3 \Rightarrow x_1
\morel x_3$.  In other words, the transitive closure of $\mrel$
relates $x_1$ to $x_2$ if $\mrel$ does, but also includes everything
$x_2$ relates to, and anything related to that, and so on.  The
transitive closure of $\step$ captures the notion of ``steps in one or
more steps''.  Composing these closure operations gives $\multistep$,
which is ``steps in zero or more steps.''  Writing it out explicitly
results in the following set of inference rules:

\begin{mathpar}
\inferrule*{e \step e'}
           {e \multistep e'}

\inferrule*{\ }
           {e \multistep e}

\inferrule*{e \multistep e' \\ e' \multistep e''}
           {e \multistep e''}

\end{mathpar}

The above semantics are a ``\deftech{small-step}'' or
``\deftech{reduction}'' semantics.  Unlike the natural semantics, the
reduction semantics accounts for each step of a computation.  Although
it's immaterial for the $\Arith$ language, the small-step approach has
some advantages over big-step (as we should expect considering it is
considerably more involved); one of the most important advantages
comes into play when the object language is sufficiently powerful to
include non-terminating computations.  Since the natural semantics is
concerned only with final answers, it doesn't say much about
non-terminating programs, while reduction semantics can still be used
to reason about the (infinite) steps of such a computation.


One important observation to make is that although we've constructed
an alternative semantics, we can formally relate these two semantics.
In particular, we can recover a big-step evaluation relation from the
reduction semantics.  Consider the following relation $\downarrow\;
\subseteq \Arith \times \mathbb{Z}$:
\[
\inferrule*{e \multistep i}
           {e \downarrow i}
\]
which is a subset of $\multistep$, restricted to the case of the right
hand side being an integer.  This relation effectively forgets any
intermediate terms in a computation and just relates expressions to
their irreducible values.  This relation, although defined
differently, is the same relation as $\Downarrow$.  Seen this way, it
is accurate to say natural semantics are an \deftech{abstraction} of
reduction semantics, and reduction semantics are a
\deftech{refinement} of natural semantics.


To model the reduction semantics in OCaml, we can first define the
axiomatic reduction relation, $\areducename$.  First, observe that
$\areducename$ is a \emph{function}; if $\areduce\mexp{\mexp'}$ and
$\areduce\mexp{\mexp''}$, then $\mexp' = \mexp''$.  Therefore we can
model the relation as a function on expressions.  However,
$\areducename$, when viewed as a function, is \emph{partial}; not all
expressions reduce according to $\areducename$.  For example, $\mint
\not\areducename\; \mexp$, for any $\mexp$.

We can model a partial function from expressions to integers as a
total function from expressions to an integer options.  Optional types
are a useful way to encode either getting something or nothing:
\begin{verbatim}
type 'a option =
  | None
  | Some of 'a
\end{verbatim}
This type is so useful, it's built in.  Now defining $\areducename$ in
OCaml consists in translating the defining judgements into an OCaml
function:
\begin{verbatim}
   let a (e : arith) : arith option =
     match e with
       | Pred (Int i) -> Some (Int (i-1))
       | Succ (Int i) -> Some (Int (i+1))
       | Plus (Int i, Int j) -> Some (Int (i+j))
       | Mult (Int i, Int j) -> Some (Int (i*j))
       | _ -> None
\end{verbatim}
Some examples:
\begin{verbatim}
   # a (Int 4);;
   - : arith option = None

   # a (Succ (Int 5));;
   - : arith option = Some (Int 6)

   # a (Plus (Succ (Int 5), Succ (Int 4)));;
   - : arith option = None
\end{verbatim}

To characterize $\step$, which is not a function, but a more general
relation, which means we need to represent $\step$ as a function from
expressions to \emph{sets of} expressions.  We can encode this set as
a list.  Therefore the signature of {\tt step\_a} will be {\tt arith ->
  arith list}:
\begin{verbatim}
   let rec step_a (e : arith) : arith list =
     match a e with
       | None ->
           (match e with
              | Int i -> []
              | Pred e -> List.map (fun e' -> Pred e') (step_a e)
              | Succ e -> List.map (fun e' -> Succ e') (step_a e)
              | Plus (e1, e2) ->
                  let f e1s e2s = List.map
                    (fun (e1',e2') -> Plus (e1', e2'))
                    (cartesian e1s e2s)
                  in
                    (f (step_a e1) [e2]) @ (f [e1] (step_a e2))
              | Mult (e1, e2) ->
                  let f e1s e2s = List.map
                    (fun (e1',e2') -> Mult (e1', e2'))
                    (cartesian e1s e2s)
                  in
                    (f (step_a e1) [e2]) @ (f [e1] (step_a e2)))
       | Some e' -> [e']
\end{verbatim}
where
\begin{verbatim}
   let cartesian (l : 'a list) (l' : 'b list) : ('a * 'b) list =
     List.concat (List.map (fun e -> List.map (fun e' -> (e,e')) l') l)
\end{verbatim}
Some examples:
\begin{verbatim}
   # step_a (Int 4);;
   - : arith list = []

   # step_a (Succ (Int 5));;
   - : arith list = [Int 6]

   # step_a (Plus (Succ (Int 5), Succ (Int 4)));;
   - : arith list = [Plus (Int 6, Succ (Int 4)); Plus (Succ (Int 5), Int 5)]
\end{verbatim}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{exercise}
Prove $e \Downarrow i \iff e \downarrow i$.
\end{exercise}

\begin{exercise}
Is $\reduce$ a function?  Is $\step$?  In each case, either
  prove the relation is a function or give an example of an expression
  that relates to two distinct expressions.
\end{exercise}

\begin{exercise}
The $\step$ relation codifies the notion of ``takes exactly one step
of arithmetic reduction.'' In other words, any proof tree of $e \step
e'$ involves exactly one use of the $\reduce$ rule. (You could prove
this if you'd like.)  In terms of grade-school arithmetic, this is the
``show each step of your work'' semantics, which doesn't let you skip
any steps ($\Downarrow$ lets you skip all of the steps and just give
the answer) or do any work in parallel.  Design an alternative
semantics, $\laxparstep$, that allows multiple subexpressions to
reduce (one step) in parallel.
  %
  So for example, $\Plus(\Succ(3),\Pred(5))
  \laxparstep \Plus(4,4)$.
  %
  Note that this semantics should not let you conclude that
  $\Plus(\Succ(3),\Pred(5)) \laxparstep 8$
  in just one step.
  %

  You have a design choices to make for $\laxparstep$: it can allow
  any amount of parallelism, or it can impose a maximal amount of parallelism.
  %
  Let's call the more lax any amount of parallelism relation
  $\laxparstep$ and the maximal one $\maxparstep$.  The key difference
  is that $\laxparstep$ should relate
  $\Plus(\Succ(3),\Pred(5))$ to
  $\Plus(4,\Pred(5))$, while $\maxparstep$ should not
  since there was more work that could have been done in parallel.
  Design both.  Is $\laxparstep$ a function?  Is $\maxparstep$?
  Is $\laxparstep$ equal to $\multistep$?  Is $\maxparstep$?
\end{exercise}

\begin{exercise}
To give away an answer to an earlier question, $\step$ is \emph{not} a
function.  To see why, consider $\Plus(\Succ(3),\Pred(5))$.  In one
step, this program can either become $\Plus(4,\Pred(5))$ or
$\Plus(\Succ(3),4)$.  So modelling $\step$ as a function in, say,
OCaml can't be accomplished quite so easily as with $\Downarrow$.  One
idea for modelling a finite relation in a functional language is to
rely on the isomorphism
\[
(X \times X) \cong (X \longrightarrow \mathcal{P}(X))\text.
\]
This is to say, we can represent a relation as a function from
an element to the \emph{set} of elements it relates to.
%
With this idea in mind, write an OCaml function \syntax{step} that
represents $\step$.
\end{exercise}

\begin{exercise}
To give away yet another answer, $\reduce$ is a function, but it is a
\deftech{partial function}---it is not defined all elements of
$\Arith$.  One idea for representing a partial function in a
functional language is to rely on the isomorphism
\[
(X \rightharpoonup X) \cong (X \longrightarrow (\emptyset + \{X\}))\text.
\]
This is to say, we can represent a partial function as a total
function to either the empty set (interpreted as undefined) or a
single set consisting of the element the partial function maps to.
This has the nice property that it is consistent with the functional
view of relations from the previous exercise, since
\[
(X \longrightarrow (\emptyset + \{X\})) \subseteq
(X \longrightarrow \mathcal{P}(X))\text.
\]
Write an OCaml function \syntax{reduce} that represents $\reduce$
using the above idea.
\end{exercise}

\begin{exercise}
The compatible closure of a relation over the syntax of $\Arith$
expressions can be seen as a function that consumes an $\Arith$
relation and produces a new $\Arith$ relation. From the functional
perspective of relations, this means the compatible closure operation
(for $\Arith$) is a function with the following signature:
\begin{align*}
\syntax{compat} : (\Arith \longrightarrow \mathcal{P}(\Arith)) \longrightarrow (\Arith \longrightarrow \mathcal{P}(\Arith))
\end{align*}
%
Design an OCaml function \syntax{compat} that computes the compatible
closure of its argument.  Test the following conjecture: \syntax{step}
= \syntax{compat reduce}.
\end{exercise}

\begin{exercise}
The transitive and reflexive closure operations are functions that
consume a relation and produce a new relation.  Using the functional
view of relations, this means they are functions with the following
signatures:

\begin{align*}
\syntax{refl} : (X \longrightarrow \mathcal{P}(X)) \longrightarrow (X \longrightarrow \mathcal{P}(X))\\
\syntax{trans} : (X \longrightarrow \mathcal{P}(X)) \longrightarrow (X \longrightarrow \mathcal{P}(X))\\
\end{align*}
%
Design OCaml functions for \syntax{refl} and \syntax{trans}.  Test the
following conjecture: \syntax{refl (trans step)} = \syntax{trans
  (refl step)}.  The \syntax{refl} function is easy.  The
\syntax{trans} function is less so because it's not obvious when to
stop iterating the given relation, but this exercise demonstrates a
powerful idea we'll see again and again, which is the iterative
computation of \deftech{fixed points}.

The idea here is that \syntax{trans}, given a relation $\mrel$,
computes a relation $\morel$, written here as a function:
\begin{align}
\morel(x) &= \{x'\ |\ x \mrel x'\} \\
&\cup \{x'\ |\ x \mrel x_0 \mrel x'\}\\
&\cup \{x'\ |\ x \mrel x_0 \mrel x_1 \mrel x'\}\\
&\vdots
\end{align}
%
The elipsis are elliding an infinite number of equations here, but if
the codomain of $\morel$ is finite, we know that only a finite number
of equations will ever be used.  Moreover, notice that the $x_0$ of
(7) is just the $x'$ of (6).  Likewise, the $x_1$ of (8) is just the
$x'$ of (7).  So if you want to compute $\morel(x)$ you can start with
the set $\mrel(x)$.  For each $x'$ in this set, compute $\mrel(x')$
and add it in to the set (you've reached a fixed point!).  Keep doing
this until $\mrel$ doesn't add anything new to the set.  This is
$\morel(x)$.
\end{exercise}


\subsection{Reduction in Context}
\label{sec:context}

When an expression reduces, there is a subexpression being reduced
according to a reduction axiom.  This occurs within a surrounding
expression, or \emph{context}.  We can formalize the notion of context
and by doing so, enable new kinds of reductions.

A \deftech{context} can be thought of as an expression with a hole in
it, which is just a term in the following language:
\[
\begin{array}{llcl}
\mathit{Context} & \mctx & = & \hole \\
                 &       & | & \Pred(\mctx)\ |\ \Succ(\mctx)\\
                 &       & | & \Plus(\mctx,\mexp)\ |\ \Plus(\mexp,\mctx)\\
                 &       & | & \Mult(\mctx,\mexp)\ |\ \Mult(\mexp,\mctx)\\
%%                 &       & | & \Eq(\mctx,\mexp)\   |\ \Eq(\mexp,\mctx)\\
%%                 &       & | & \Div(\mctx,\mexp)\ |\ \Div(\mexp,\mctx)\\
%%                 &       & | & \If(\mctx,\mexp,\mexp)\ |\ \If(\mexp,\mctx,\mexp)\ |\ \If(\mexp,\mexp,\mctx)
\end{array}
\]
A context is either a hole, written ``$\hole$,'' or it's a term
constructor with a context in place of a subexpression.  An expression
can be plugged into a context to obtain another expression, which is
written ``$\plug\mctx\mexp$,'' which means ``replace the occurrence of
$\hole$ in $\mctx$ with $\mexp$.'' To be more formal, the plug
function is defined as:
\begin{align*}
\plug\hole\mexp &= \mexp\\
\plug{\Pred(\mctx)}\mexp &= \Pred(\plug\mctx\mexp)\\
\plug{\Succ(\mctx)}\mexp &= \Succ(\plug\mctx\mexp)\\
\plug{\Plus(\mctx,\mexp')}\mexp &= \Plus(\plug\mctx\mexp,\mexp')\\
\plug{\Plus(\mexp',\mctx)}\mexp &= \Plus(\mexp',\plug\mctx\mexp)\\
\plug{\Mult(\mctx,\mexp')}\mexp &= \Mult(\plug\mctx\mexp,\mexp')\\
\plug{\Mult(\mexp',\mctx)}\mexp &= \Mult(\mexp',\plug\mctx\mexp)\\
\end{align*}
The notation ``$\plug\mctx\mexp$'' is also overloaded to mean ``an
expression $\mexp'$ such that $\mexp' = \plug\mctx\mexp$.''  We say
$\mexp'$ can be ``decomposed'' into $\mctx$ and $\mexp$.

This notation allows us to give an alternative, but equivalent,
formulation of the compatible closure of $\areducename$ as:
\begin{mathpar}
\inferrule*{\areduce\mexp{\mexp'}}
          {{\plug\mctx\mexp} \step {\plug\mctx{\mexp'}}}
\end{mathpar}
This rule states: ``if an expression can be decomposed into a context
$\mctx$ with $\mexp$ in the hole, and $\mexp$ reduces to $\mexp'$ by
the reduction axiom, then the program steps to $\mctx$ with $\mexp'$
plugged in the hole.''

This context-based formulation may seem like just a somewhat more
compact notation for specifying the tedious compatibility inference
rules that allow reduction to happen inside of subexpressions, but it
also does something more significant: it gives a name to the context in
which a reduction occurs; naming something gives us control over
it.\footnote{Computer science is in many ways the science of names.}
We will examine some of the possibilities later in the notes.


\subsection{Standard Reduction Machine}

The reduction semantics for $\Arith$ allows a single program to reduce
in multiple different ways, just as we may simplify
$(2+4)\cdot((6-1)+(1+1))$ in a number of different ways by selecting
different orders in which to simplify subexpressions. We know from the
consistency of the language that no matter which order we choose, if
we get an answer, it is \emph{the} answer; redoing the calculation in
another order will not change the final result.

Having a ``calculus of programs,'' as embodied by the equational
theory for our language, is important to reason about programs and
equivalences between them, but when trying to find what a program
reduces it, it's better if we had a strategy for the mechanical
calculation of answers.  For the $\Arith$ language, it's easy to see
that any strategy will do: as long as you keep reducing something,
you'll always find the correct answer eventually; it doesn't matter
what order you go in.  For richer languages, it's not always clear
that there's a fixed strategy for finding answers (if an answer even
exists!).


Establishing a strategy for the order in which a machine applies
reduction axioms to obtain an answer is called a \deftech{standard
  reduction semantics}; it represents a canonical way in which programs
are reduced.


%% This is not the case for $\Barith$, which is inconsistent---we can
%% arrive at two totally different answers by calculating in different
%% orders.  That's usually not desirable.  Moreover, even if a system is
%% consistent, we often want to reason about a particular strategy for
%% reducing programs; we often want a \emph{standard reduction relation}.


Let's develop a standard reduction relation, called $\astdstep$, for
$\Arith$.  (Take note of the long barred arrow used here; don't
confuse the $\longmapsto$ and $\rightarrow$ arrows!) The idea here is
to make the one-step reduction relation a function by standardizing
the reduction strategy:

\begin{mathpar}
\inferrule{\areduce\mexp{\mexp'}}
          {\mexp \astdstep \mexp'}

\inferrule{\mexp_1 \astdstep \mexp_1'}
          {\Plus(\mexp_1,\mexp_2) \astdstep \Plus(\mexp_1',\mexp_2)}

\inferrule{\mexp \astdstep \mexp'}
          {\Plus(\mval,\mexp) \astdstep \Plus(\mval,\mexp')}

\inferrule{\mexp_1 \astdstep \mexp_1'}
          {\Mult(\mexp_1,\mexp_2) \astdstep \Mult(\mexp_1',\mexp_2)}

\inferrule{\mexp \astdstep \mexp'}
          {\Mult(\mval,\mexp) \astdstep \Mult(\mval,\mexp')}

\inferrule{\mexp \astdstep \mexp'}
          {\Succ(\mexp) \astdstep \Succ(\mexp')}

\inferrule{\mexp \astdstep \mexp'}
          {\Pred(\mexp) \astdstep \Pred(\mexp')}
\end{mathpar}

Notice that none of the rules overlap.  To see this, consider a
more elaborate, but equivalent formulation of the rules for $\Mult$:
\begin{mathpar}
\inferrule{\mexp_1 \astdstep \mexp_1' \\ \mexp_1 \not\in \mathit{Val}}
          {\Mult(\mexp_1,\mexp_2) \astdstep \Mult(\mexp_1',\mexp_2)}

\inferrule{\mexp \astdstep \mexp' \\ \mexp \not\in \mathit{Val}}
          {\Mult(\mval,\mexp) \astdstep \Mult(\mval,\mexp')}
\end{mathpar}
The added hypotheses are in fact redundant because $\mexp \astdstep
{\mexp'}$ implies $\mexp$ is not a value, but it's now easy to see
by case analysis that at most one rule applies to an expression of the
form $\Mult(\mexp_1,\mexp_2)$ because either $e_1$ is not a value, in
which case the leftmost rule applies, or $e_1$ is a value, but $e_2$
is not, in which case the rightmost rule applies, or both $\mexp_1$
and $\mexp_2$ are values, in which case the $\areducename$ rule
applies.

The rules for reducing inside expressions are not quite compatibility
rules because they do not allow a reduction axiom to be applied to
\emph{any} subexpression.  Instead, they encode a \deftech{reduction
  strategy} that specifies the one subexpression where an axiom may be
applied.

We can represent the $\astdstep$ relation in OCaml like we did for
$\areducename$:

\begin{verbatim}
   let rec standard_step_a (e : arith) : arith list =
     match a e with
       | None ->
           (match e with
              | Int i -> []
              | Pred e -> List.map (fun e' -> Pred e') (step_a e)
              | Succ e -> List.map (fun e' -> Succ e') (step_a e)
              | Plus (e1, e2) ->
                  let f e1s e2s = List.map
                    (fun (e1',e2') -> Plus (e1', e2'))
                    (cartesian e1s e2s)
                  in
                    (match e1 with
                      | Int i -> (f [e1] (standard_step_a e2))
                      | _ -> (f (standard_step_a e1) [e2]))
              | Mult (e1, e2) ->
                  let f e1s e2s = List.map
                    (fun (e1',e2') -> Mult (e1', e2'))
                    (cartesian e1s e2s)
                  in
                    (match e1 with
                       | Int i -> (f [e1] (standard_step_a e2))
                       | _ -> (f (standard_step_a e1) [e2])))
       | Some e' -> [e']
\end{verbatim}

Some examples:
\begin{verbatim}
   # standard_step_a (Int 4);;
   - : arith list = []

   # standard_step_a (Plus (Succ (Int 5), Succ (Int 4)));;
   - : arith list = [Plus (Int 6, Succ (Int 4))]
\end{verbatim}

You should be able to convince yourself that {\tt standard\_step\_a}
always produces either an empty list or a singleton list.  In other
words, $\astdstep$ is a partial function, being encoded here as a
relation.  We could rewrite the code to produce an {\tt arith option},
or we could use a function to provide that interface:
\begin{verbatim}
   let rel_to_partial_func (r : ('a -> 'a list)) : ('a -> 'a option) =
     fun a ->
       match r a with
         | [] -> None
         | a::_ -> Some a
\end{verbatim}

Now we can compute an alternative interface for standard reduction:
\begin{verbatim}
   let standard_step_a' = rel_to_partial_func standard_step_a
\end{verbatim}

Some examples:
\begin{verbatim}
   # standard_step_a' (Int 4);;
   - : arith option = None

   # standard_step_a' (Plus (Succ (Int 5), Succ (Int 4)));;
   - : arith option = Some (Plus (Int 6, Succ (Int 4)))
\end{verbatim}



Instead of specifying the strategy by way of progress rules, the
same strategy can also be defined through the use of
contexts, but instead of using arbitrary contexts, we will specify the
subset of contexts in which reduction may occur.  These contexts are
called \emph{evaluation contexts}:
\[
\begin{array}{llcl}
\mathit{EvalContext} & \mectx & = & \hole \\
                 &       & | & \Pred(\mectx)\ |\ \Succ(\mectx)\\
                 &       & | & \Plus(\mectx,\mexp)\ |\ \Plus(\mval,\mectx)\\
                 &       & | & \Mult(\mectx,\mexp)\ |\ \Mult(\mval,\mectx)\\
\end{array}
\]
And standard reduction is just:
\begin{mathpar}
\inferrule{\areduce\mexp{\mexp'}}
          {\plug\mectx\mexp \astdstep \plug\mectx{\mexp'}}
\end{mathpar}

It's possible to read off the reduction strategy from the grammar.
For example, the production $\Plus(\mectx,\mexp)$ says ``until the
left side of $\Plus$ is a value, reduce the left side of $\Plus$'' and
$\Plus(\mval,\mectx)$ says ``after the left side is value, reduce the
right side.''  So when you see $\Plus(\mexp_1,\mexp_2)$, you know all
of the reductions will first happen for $\mexp_1$, and only after
there are no more will all of the reductions for $\mexp_2$ happen.


The standard semantics has the following desirable properties:
\begin{enumerate}
%% \item it is a function,
%% \[
%% \bvstdstep\menv\mexp{\mexp'} \wedge
%% \bvstdstep\menv\mexp{\mexp''} \Rightarrow \mexp'=\mexp''\text,
%% \]
\item if the standard semantics produces a value, it is consistent with the reduction semantics,
\[
\mexp\astdmultistep\mval \Rightarrow \mexp  \multistep \mval\text,
\]

\item if the reduction semantics produces a value, the standard semantics does too,
\[
\mexp\multistep\mval \Rightarrow \mexp\astdmultistep\mval\text.
\]
\end{enumerate}

Our goal with the standard semantics was to settle on a canonical
strategy for reducing programs.  The properties above tell us that
this canonical strategy (1) never produces something inconsistent with
the semantics, and (2) always produces a value, if there is one.

These two properties tell us the standard semantics we have is a good
basis for the specification of an interpreter, which can be defined by
the iteration of the standard reduction function.

\paragraph{Note on the literature:} Since the canonical reduction strategy
is often what we are concerned with when reasoning about programs,
most PL papers formulate only the standard reduction and are not
concerned with the syntactic theory of their language, which establishes
algebraic laws for proving the equality of programs.

\begin{exercise}
Prove $\mexp\astdmultistep\mval \iff \mexp \multistep \mval$.
\end{exercise}

% \subsubsection{Standard Reduction for $\Arith$ in OCaml}

We can model evaluation contexts as a data type in OCaml:
\begin{verbatim}
type ecxt  = Hole
           | EPred of ecxt
           | ESucc of ecxt
           | EPlusL of ecxt * arith
           | EPlusR of int * ecxt
           | EMultL of ecxt * arith
           | EMultR of int * ecxt
\end{verbatim}
The function to plug an expression into a context is straightforward:
\begin{verbatim}
let rec plug (c : ecxt) (e : arith) : arith =
  match c with
    Hole -> e
  | EPred c -> Pred (plug c e)
  | ESucc c -> Succ (plug c e)
  | EPlusL (c, e') -> Plus (plug c e, e')
  | EPlusR (i, c) -> Plus (Int i, plug c e)
  | EMultL (c, e') -> Mult (plug c e, e')
  | EMultR (i, c) -> Mult (Int i, plug c e)
\end{verbatim}
Decomposing a program into an evaluation context and a potential redex
is easy too, although decomposition is undefined on values, so we
need to model decompose as a partial function:
\begin{verbatim}
let rec decompose (e : arith) : (ecxt * arith) option =
  match e with
    Int i -> None
  | Pred (Int i) -> Some (Hole, e)
  | Succ (Int i) -> Some (Hole, e)
  | Plus (Int i, Int j) -> Some (Hole, e)
  | Mult (Int i, Int j) -> Some (Hole, e)
  | Pred e ->
    let Some (c', e') = decompose e in Some (EPred c', e')
  | Succ e ->
    let Some (c', e') = decompose e in Some (ESucc c', e')
  | Plus (Int i, e) ->
    let Some (c', e') = decompose e in Some (EPlusR (i, c'), e')
  | Plus (e, e2) ->
    let Some (c', e') = decompose e in Some (EPlusL (c', e2), e')
  | Mult (Int i, e) ->
    let Some (c', e') = decompose e in Some (EMultR (i, c'), e')
  | Mult (e, e2) ->
    let Some (c', e') = decompose e in Some (EMultL (c', e2), e')
\end{verbatim}
This code relies on the following (easy to prove) fact that if an
expression is not a value, then it decomposes into an evaluation
context and potential redex.  This means the non-exhaustive pattern
matching warnings the compiler emits are spurious.

The evaluation function just iterates the decompose, reduce, plug
process until a value is reached:
\begin{verbatim}
let rec eval (e : arith) : int =
  match e with
    Int i -> i
  | _ ->
    let Some (c, e') = decompose e in
    let Some r = a e' in
    eval (plug c r)
\end{verbatim}
In {\tt decompose e} we know that {\tt e} is not a value, so {\tt
  decompose} is defined on {\tt e} (i.e.~we cannot get {\tt None}),
and further more, {\tt e'} is a redex, hence {\tt a e'} is
defined, so none of these pattern matches can fail.

A quick ``proof by example'' confirms that {\tt eval} produces the
same results as the OCaml implementation of the natural semantics from
section~\ref{sec:natural}:
\begin{verbatim}
# eval (Plus (Int 4, Succ (Int 2)));;
- : int = 7
\end{verbatim}

\subsection{Compiling}

What is a compiler?

One view is the following: a compiler is a function that consumes a
program and produces a program, which when run produces the same
result as the given program.

In other words,
\begin{verbatim}
   let compile (e : arith) : (unit -> int) = ...
\end{verbatim}
such that
\begin{alltt}
   \(\forall\)e. compile e () = eval e
\end{alltt}

Make a correct compiler is trivial:
\begin{verbatim}
   (* Correct compiler, ground truth *)
   let rec compile_0 (e : arith) : (unit -> int) =
     (fun () -> eval e)

   (* Simple test *)
   let p = (Plus (Int 1, Int 2)) in
     eval p = compile_0 p ();;
\end{verbatim}
While this compiler is trivial, it does create an explicit distinction
between \emph{compiling} and \emph{running}.  Code outside the {\tt
  fun} is the compile-time code; code inside the {\tt fun} is run-time
code.  The trivial compiler says at compile time, do nothing; at
run-time, run the interpreter.  Perfectly sensible.


We could however have the compiler actually do some work and hope to
reap the benefits at run-time.  Taken to its logical conclusion, the
compiler could just do \emph{all} of the work, then generate code that
returns the result:
\begin{verbatim}
   (* Optimal inlining compiler *)
   let rec compile_1 (e : arith) : (unit -> int) =
     let i = eval e in
       (fun () -> i)
\end{verbatim}
This compiler runs the program at compile-time and produces a constant
function that returns the result.  This approach won't work for richer
languages, but it's not a bad way to optimize languages with decidable
evaluation relations (such as $\Arith$).

A more scalable thing to do is to compile away the run-time overhead
of syntactic case analysis for the expression being run:
\begin{verbatim}
   (* Tagless run-time *)
   let rec compile_2 (e : arith) : (unit -> int) =
     match e with
       | Int i -> (fun () -> i)
       | Pred e ->
          let c = compile_2 e in
            (fun () -> c () - 1)
       | Succ e ->
          let c = compile_2 e in
            (fun () -> c () + 1)
       | Plus (e1, e2) ->
          let c1 = compile_2 e1 in
          let c2 = compile_2 e2 in
            (fun () -> c1 () + c2 ())
      | Mult (e1, e2) ->
          let c1 = compile_2 e1 in
          let c2 = compile_2 e2 in
            (fun () -> c1 () * c2 ())
\end{verbatim}

Notice that at run-time, the code does not dispatch on the kind of
expression is being run; there's nothing left at run-time but OCaml's
arithmetic operations and function calls to run code.



\subsection{Again, with Ambiguity}

Let's now replay the development of the various formulations of
$\Arith$ with the slightest addition to the language.  Let's add the
following form of expression: $\Amb(\mexp_1,\mexp_2)$, which we'll
take to mean ``evaluate, ambiguously, to either the value of $\mexp_1$
or $\mexp_2$''.

\subsubsection{Natural Semantics}

It's straightforward to extend the evaluation relation to cover the
$\Amb$ form:
\begin{mathpar}
\inferrule{\mexp_1 \Downarrow \mint}
          {\Amb(\mexp_1,\mexp_2) \Downarrow \mint}

\inferrule{\mexp_2 \Downarrow \mint}
          {\Amb(\mexp_1,\mexp_2) \Downarrow \mint}
\end{mathpar}
However, this changes $\Downarrow$ from being a function from
expressions to integers to a \emph{relation} from expressions to
integers.  Because of this, we will run into trouble with our {\tt
  eval} function in OCaml.  Consider the following naive translation
of the mathematical definition of $\Downarrow$ into OCaml in the
presence of $\Amb$:
\begin{verbatim}
   type arith =
     | Int of int
     | Pred of arith
     | Succ of arith
     | Plus of arith * arith
     | Mult of arith * arith

   let rec eval (e : arith) : int =
       match e with
       | Int i -> i
       | Pred e -> (eval e) - 1
       | Succ e -> (eval e) + 1
       | Plus (e1, e2) -> (eval e1) + (eval e2)
       | Mult (e1, e2) -> (eval e1) * (eval e2)
       | Amb (e1, e2) -> eval e1
       | Amb (e1, e2) -> eval e2
\end{verbatim}
The problem here is that the left-hand sides of the $\Amb$ cases
overlap.  Since OCaml performs pattern matching in order, the last
case is not reachable, and the OCaml compiler will tell us as much:
\begin{verbatim}
      | Amb (e1, e2) -> eval e2;;
        ^^^^^^^^^^^^
Warning 11: this match case is unused.
val eval : arith -> int = <fun>
\end{verbatim}

The problem here is the mismatch between the eval function and the
$\Downarrow$ relation.  An idea to address the problem is to represent
the relation as a function from expressions to \emph{sets of}
integers.  While OCaml has a nice, general purpose set library, an
easy hack is to represent a set as a list.  Therefore the signature of
{\tt eval} will be {\tt arith -> int list}.

Let's take the function in pieces:
\begin{verbatim}
let rec eval (e : arith) : int list =
  match e with
\end{verbatim}
The base case is easy: when given an integer, produce the list of its
results, which is just a list consisting of that integer:
\begin{verbatim}
  | Int i -> [i]
\end{verbatim}
When we recursively evaluate subexpressions, we no longer get an
integer back, but instead a list of integers.  In the case of $\Pred$,
we must then subtract one from each element to obtain the final result:
\begin{verbatim}
  | Pred e' -> List.map (fun v -> v-1) (eval e')
\end{verbatim}
Successor is similar:
\begin{verbatim}
  | Succ e' -> List.map (fun v -> v+1) (eval e')
\end{verbatim}
In the case of multiple subexpressions, we will have multiple lists of
integers to combine into the final result.  Suppose we have
$\Plus(\mexp_1,\mexp_2)$ where
\begin{alltt}
   eval e1 \(=\) [1; 2; 3]
   eval e2 \(=\) [5; 10]
\end{alltt}
Then we want to compute the sums of
\begin{verbatim}
   [(1, 5); (2, 5); (3, 5); (1, 10); (2, 10); (3, 10)]
\end{verbatim}
which is
\begin{verbatim}
   [6; 7; 8; 11; 12; 13]
\end{verbatim}
To compute the first list, we just use our helper function for computing
the Cartesian product of two given lists.
%
Now the cases for addition and multiplication are easy:
\begin{verbatim}
  | Plus (e1, e2) ->
      List.map (fun (v1,v2) -> v1+v2) (cartesian (eval e1) (eval e2))
  | Mult (e1, e2) ->
      List.map (fun (v1,v2) -> v1*v2) (cartesian (eval e1) (eval e2))
\end{verbatim}
Finally we have the case of $\Amb$.  Suppose we have $\Amb(\mexp_1,\mexp_2)$ where,
as before,
\begin{alltt}
   eval e1 \(=\) [1; 2; 3]
   eval e2 \(=\) [5; 10]
\end{alltt}
Here we want to produce a list of all of the elements in either list,
so the thing to do is append the two lists together:
\begin{verbatim}
   | Amb (e1, e2) -> eval e1 @ eval e2
\end{verbatim}
Putting it all together, we have:
\begin{verbatim}
let rec eval (e : arith) : int list =
  match e with
  | Int i -> [i]
  | Pred e ->
      List.map (fun v -> v-1) (eval e)
  | Succ e ->
      List.map (fun v -> v+1) (eval e)
  | Plus (e1, e2) ->
      List.map (fun (v1,v2) -> v1+v2) (cartesian (eval e1) (eval e2))
  | Mult (e1, e2) ->
      List.map (fun (v1,v2) -> v1*v2) (cartesian (eval e1) (eval e2))
  | Amb (e1, e2) -> eval e1 @ eval e2
\end{verbatim}


\subsubsection{Reduction Semantics}

Adding reduction axioms for $\Amb$ are straightforward:
\begin{mathpar}
\inferrule*{\ }
           {\areduce{\Amb(\mint,\moint)}{\mint}}

\inferrule*{\ }
           {\areduce{\Amb(\mint,\moint)}{\moint}}
\end{mathpar}
But just as $\Downarrow$ went from being a function to a relation once
$\Amb$ was added, $\areducename$, goes from a (partial) function to a
relation.  So we can no longer represent $\areducename$ as a partial
function in OCaml and switch to a relation encoding:
\begin{verbatim}
   let a (e : arith) : arith list =
     match e with
       | Pred (Int i) -> [Int (i-1)]
       | Succ (Int i) -> [Int (i+1)]
       | Plus (Int i, Int j) -> [Int (i+j)]
       | Mult (Int i, Int j) -> [Int (i*j)]
       | Amb (Int i, Int j) -> [Int i; Int j]
       | _ -> []
\end{verbatim}

This necessitates a change to {\tt step\_a} and {\tt standard\_step\_a}.


%% \subsection{Stack Machine}

%% [TODO]
