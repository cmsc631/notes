\newcommand\typevaljudge[3]{{#1}\vdash{#2}:{#3}}
\newcommand\mtype{t}
\newcommand\typeof{\mathit{typeof}}
\newcommand\treduce{\mathbf{t}}
\newcommand\mtans{ta}
\newcommand\Ans{\mathit{Ans}}
\newcommand\TyAns{\mathit{TyAns}}

\newcommand\meint{i^\dagger}
\newcommand\moeint{j^\dagger}
\newcommand\mintv{\vec\mint}
\newcommand\mointv{\vec\moint}

\newcommand\BI{\mathcal{BI}}
\newcommand\ireduce{\mathbf{i}}
\newcommand\sreduce{\mathbf{s}}
\newcommand\intvdiv{\mathop\backslash}

\newcommand\mpath{\phi}
\newcommand\mcon{c}
\newcommand\msval{sv}
\newcommand\mcset{\mathcal{T}}
\newcommand\mtcons{tc}

\newcommand\allows[2][\mpath]{#1\models #2}

\section{Reasoning About All Program Executions} %Proving the Absence of (Certain Kinds of) Errors}

It would be nice to eliminate all programs that have errors in them.
In general, it's not possible to mechanically determine if a program
will cause an error when run, so much of program analysis, which is
the study of approximations to program properties, is concerned with
detecting or proving the absense of errors in programs.  One of the
most common forms of this kind of program analysis are \deftech{type
  systems}:

\begin{quotation}
A type system is a tractable syntactic method for proving the absence
of certain program behaviors by classifying phrases according to the
kinds of values they compute.

\raggedleft --- Benjamin C.~Pierce
\end{quotation}

In its simplest form, a type system can prove the absence of errors
that arise from applying operations to the wrong kinds of values.  Like
any program analysis, the classification of programs into those that
have these kind of errors and those that do not must be approximate.
So the classification will err on the side of caution and classify
programs as \emph{definitely} not having this kinds of errors or
\emph{potentially} having them.  In other words, a type system will
misclassify some good programs as bad, but no bad program will be
classified as good.

\subsection{Classifying phrases according to the kinds of answers they compute}

If we were to consider classifying phrases according to the kinds of
answers they compute, the most precise characterization would be to
classify phrases by \emph{the set of answers} they compute.

For some simple languages, calculating such a set is trivial.  For
example, for any $\Arith$ program $\mexp$, it's easy to compute the
set $\{\mint\ |\ \mexp \Downarrow \mint \}$.
%
Even for $\Barith$, if we consider characterizing phrases $\mexp$ with
a \emph{given environment} $\menv$, then it's easy to compute $\{
\mans\ |\ \menv \vdash \mexp \Downarrow \mans \}$.  It's easy to
compute this characterization because it consists of just a single run
of the program and $\Barith$ is such a computationally feeble
language, computing the evaluation of programs is decidable.
%
But we might also want to reason about all possible executions of a
$\Barith$ program.  If we consider the environment as a model of
program inputs, provided by the external world, then it's reasonable
to consider the answers a program computes as a function of the
environment.  In other words, characterize phrases $\mexp$ by the set
$\{ \mans\ |\ \menv \vdash \mexp \Downarrow \mans\text{, for some
}\menv\}$.  The trouble is this set is potentially infinite, so
computing it could take a while.

For this reason, it may be useful to compute a more approximating
classification of the kinds of answers phrases compute.  Designing
useful approximating classifications is the art and science of
\emph{abstract interpretation}.

Let's see a simple instance of this.

Suppose we want to classify phrases not by the precise value they
compute but rather by whether they compute:
\begin{itemize}
\item an integer,
\item a boolean,
\item an error, or
\item some combination of the above.
\end{itemize}

For example, $\Mult(3, 4)$ should be characterized as computing an
integer.  $\If(\True,3,\False)$ computes a boolean.
$\If(\mvar,3,\False)$ computes a boolean, an integer, or an error,
depending on the environment.


We therefore define the following \emph{abstract answers}:
%\newcommand\mapreans{\mans^\#}
\newcommand\abs[1]{#1^{\#}}
\[
\begin{array}{llcl}
\mathit{AbstractAnswer} & \abs\mans & = & \Bool\ |\ \Int\ |\ \Err \\
%\mathit{AbstractAnswer} & \hat\mans & = & \{ \mapreans, \dots \}
\end{array}
\]

Abstract answers denote sets of answers (sometimes called ``concrete''
answers to contrast abstract answers).  Their meaning is defined as follows:
\begin{eqnarray*}
% \den{\{ \mapreans_0, \dots, \mapreans_n \}} &=& \bigcup_{i\in\{0..n\}}{\den{\mapreans_i}}\\
\den{\Bool} &=& \{ \True, \False\}\\
\den{\Int} &=& \{ \dots, -1, 0, 1, \dots\}\\
\den{\Err} &=& \{ \Err_{\Div0}, \Err_{\If}, \Err_{\Plus}, \Err_{\Succ}, \Err_{\Plus1}, \dots \}\\
\end{eqnarray*}

Now let's explore an abstract evaluation relation for $\Barith$ based
around the above notion of abstract values.  The idea here is that the
formulate an alternative relation that operates on abstract values
instead of values.  There are many abstract evaluation relations.
What makes them admissible is if they are \emph{sound}, i.e. if it
possible for an expression to compute a certain kind of answer, that
answer is in the (denotation) of the abstract answer.  Formally:

\begin{claim}
If $\menv \vdash \mexp \Downarrow \mans$ for some $\menv$, then there
exists an $\abs\mans$ such that $\vdash \mexp \Downarrow \abs\mans$ and
$\mans \in \den{\abs\mans}$.
\end{claim}

It's quite easy to make a sound, but useless abstract evaluator:

\begin{mathpar}
\inferrule{\ }
          {\vdash \mexp \Downarrow \Int}

\inferrule{\ }
          {\vdash \mexp \Downarrow \Bool}

\inferrule{\ }
          {\vdash \mexp \Downarrow \Err}
\end{mathpar}

It's almost always impossible to go the other direction to design an
abstract evaluator that is \emph{complete}, i.e.:
\begin{claim}
If $\vdash \mexp \Downarrow \abs\mans$, then there exists an $\mans$
and $\menv$ such that $\vdash \mexp \Downarrow \mans$ and $\mans \in
\den{\abs\mans}$.
\end{claim}

If we wanted to do better than the useless abstract evaluator, one
approach is to use the concrete evaluator to guide its design.  Let's
consider some concrete and abstract cases in tandem:
\begin{mathpar}
\inferrule{\menv(\mvar)=\mval}
          {\menv \vdash \mvar \Downarrow \mval}

\inferrule{\ }
          {\vdash \mvar \Downarrow \Bool}

\inferrule{\ }
          {\vdash \mvar \Downarrow \Int}
\end{mathpar}
On the left is the concrete evaluation relation for variables, which
are given meaning in terms of a particular environment.  The abstract
evaluator must handle all possible environments; since an environment
may map a variable to an integer or a boolean, the rule states that a
variable occurrence may evaluate to either $\Bool$ or $\Int$.

This may seem overly conservative; variables range over all possible
values, which mean that programs involving variables that are treated
as integers will be abstract interpreted as having errors since they
variables could stand for booleans.  This is necessary for soundness
-- indeed we could imagine running such programs with environments
that don't respect our intentions for how these variables are used.
But we will return to this question in a bit and show how we can
reason based on assumptions of how variables will be used.

Here are the concrete and abstract rules for literals:
\begin{mathpar}
\inferrule{\ }
          {\menv \vdash \mint \Downarrow \mint}

\inferrule{\ }
          {\menv \vdash \mbool \Downarrow \mbool}

\inferrule{\ }
          {\vdash \mint \Downarrow \Int}

\inferrule{\ }
          {\vdash \mbool \Downarrow \Bool}
\end{mathpar}
As you can see, the abstract evaluator is losing information; it
``forgets'' which particular number or boolean a literal evaluators to
and instead just signals the appropriate set of values the literal
belongs to.

Here are the concrete and abstract rules for $\Pred$ ($\Succ$ is
similar):
\begin{mathpar}
\inferrule{\menv \vdash \mexp \Downarrow \mint }
          {\menv \vdash \Pred(\mexp) \Downarrow \mint-1 }

\inferrule{\vdash \mexp \Downarrow \Int}
          {\vdash \Pred(\mexp) \Downarrow \Int}
\end{mathpar}
The error propogation and creation rules can likewise be read-off from
the concrete rules:
\begin{mathpar}
\inferrule{\menv \vdash \mexp \Downarrow \merr}
          {\menv \vdash \Pred(\mexp) \Downarrow \merr}

\inferrule{\menv \vdash \mexp \Downarrow \mbool}
          {\menv \vdash \Pred(\mexp) \Downarrow \Err_{\Pred}}

\inferrule{\vdash \mexp \Downarrow \Err}
          {\vdash \Pred(\mexp) \Downarrow \Err}

\inferrule{\vdash \mexp \Downarrow \Bool}
          {\vdash \Pred(\mexp) \Downarrow \Err}
\end{mathpar}
The $\Plus$ and $\Mult$ cases follow a similar pattern.

Finally, let's consider $\Div$.  When a subexpression produces an error
or evaluates a boolean follows the same pattern as above, so let's
focus soley on the ``real'' cases for $\Div$.  First, the concrete cases:
\begin{mathpar}
  \inferrule{\menv \vdash \mexp_1 \Downarrow \mint\\
    \menv \vdash \mexp_2 \Downarrow \moint}
            {\menv \vdash \Div(\mexp_1,\mexp_2) \Downarrow \lfloor \mint/\moint \rfloor}

  \inferrule{\menv \vdash \mexp_1 \Downarrow \mint\\
    \menv \vdash \mexp_2 \Downarrow 0}
            {\menv \vdash \Div(\mexp_1,\mexp_2) \Downarrow \Err_{\Div0}}
\end{mathpar}
And now the abstract cases:
\begin{mathpar}
  \inferrule{\menv \vdash \mexp_1 \Downarrow \Int\\
    \menv \vdash \mexp_2 \Downarrow \Int}
            {\menv \vdash \Div(\mexp_1,\mexp_2) \Downarrow \Int}

  \inferrule{\menv \vdash \mexp_1 \Downarrow \Int\\
    \menv \vdash \mexp_2 \Downarrow \Int}
            {\menv \vdash \Div(\mexp_1,\mexp_2) \Downarrow \Err}
\end{mathpar}
The thing to notice here is that in the abstract rules the hypotheses
are the same in both of these rules.  Since our abstraction of
integers to $\Int$ is too course-grained to distinguish between zero
and non-zero integers, there's no way to tell if evaluating a division
operation is safe.  Consequently \emph{any} program that includes a
division operation will be reported as potentially causing an error.
Even obviously error free programs like $\Div(10,2)$.



\subsection{Type Judgments}\label{sec:type-judgments}

In the language of $\Barith$ expressions, there are two kinds of data:
Booleans and integers.  We can formalize a judgment on programs that
classifies them according to the data they produce, eliminating the
possibility of errors arising from misusing data.

A type is either $\Bool$ or $\Int$:
\[
\begin{array}{llcl}
\mathit{Type} & \mtype & = & \Bool\ |\ \Int
\end{array}
\]

A \deftech{type judgment} is a ternary relation on environments,
expressions, and types:
\[
\typevaljudge\menv\mexp\mtype
\]
If a program $(\menv,\mexp)$ is related to $\mtype$ it means the
program evaluates to some value of that type:
\begin{align*}
\typevaljudge\menv\mexp\Int \Rightarrow \beval\menv\mexp\mint\\
\typevaljudge\menv\mexp\Bool \Rightarrow \beval\menv\mexp\mbool
\end{align*}
Thus the relation captures a class of well-behaved programs that do no
cause type errors.  The natural semantics employed here could either
be the one that considers erroneous programs meaningless or the
explicit error semantics.

There is a small wrinkle here having to do with divide-by-zero errors,
and even without seeing the definition of the relation, you may be
(rightfully) doubting the above claims.  Let us punt on the wrinkle
for now and consider $\Div$ banished from $\Barith$ (we will restore
it later).

At first approximation, you might think of the ``$:$'' as a strange
kind of evaluation relation, which gives an approximation of the
``real'' relation ``$\Downarrow$.''  Instead of saying exactly what an
expression evaluates to, the ``:'' says what set of values the result
belongs to.  That intuition can guide the definition of the relation.
So for example, an integer expression evaluates to something in
$\Int$, and a Boolean evaluates to something in $\Bool$:
\begin{mathpar}
\inferrule{\ }
          {\typevaljudge\menv\mint\Int}

\inferrule{\ }
          {\typevaljudge\menv\mbool\Bool}
\end{mathpar}
Likewise, variables bound to integers and Booleans behave similarly:
\begin{mathpar}
\inferrule{\menv(\mvar) = \mint}
          {\typevaljudge\menv\mvar\Int}

\inferrule{\menv(\mvar) = \mbool}
          {\typevaljudge\menv\mvar\Bool}
\end{mathpar}
If an expression $\mexp$ evaluates to something in $\Int$, so does
$\Succ(\mexp)$ and $\Pred(\mexp)$:
\begin{mathpar}
\inferrule{\typevaljudge\menv\mexp\Int}
          {\typevaljudge\menv{\Pred(\mexp)}\Int}

\inferrule{\typevaljudge\menv\mexp\Int}
          {\typevaljudge\menv{\Succ(\mexp)}\Int}
\end{mathpar}
If expressions $\mexp_1$ and $\mexp_2$ evaluate to values in $\Int$,
then $\Plus(\mexp_1,\mexp_2)$ and $\Mult(\mexp_1,\mexp_2)$ evaluate to
values in $\Int$ and $\Eq(\mexp_1,\mexp_2)$ evaluates to values in
$\Bool$:
\begin{mathpar}
\inferrule{\typevaljudge\menv{\mexp_1}\Int \\
           \typevaljudge\menv{\mexp_2}\Int}
          {\typevaljudge\menv{\Plus(\mexp_1,\mexp_2)}\Int}

\inferrule{\typevaljudge\menv{\mexp_1}\Int \\
           \typevaljudge\menv{\mexp_2}\Int}
          {\typevaljudge\menv{\Mult(\mexp_1,\mexp_2)}\Int}

\inferrule{\typevaljudge\menv{\mexp_1}\Int \\
           \typevaljudge\menv{\mexp_2}\Int}
          {\typevaljudge\menv{\Eq(\mexp_1,\mexp_2)}\Bool}
\end{mathpar}
Finally, there is the matter of $\If$.  It's clear that the test
expression $\If(\mexp_1,\mexp_2,\mexp_3)$ should evaluate to some
value in $\Bool$, but what should the whole expression evaluate to?
If all we know of $\mexp_1$ is it evaluates to a Boolean, then the
whole expression either evaluates to the value of $\mexp_1$ or
$\mexp_2$.  But which is it?  One approach is to require $\mexp_1$ and
$\mexp_2$ to evaluate to values within the same set.  You've probably
encountered this before: both branches of an $\If$ must have the same
type.  Adopting this approach, the rule is:
\begin{mathpar}
\inferrule{\typevaljudge\menv{\mexp_1}\Bool\\
           \typevaljudge\menv{\mexp_2}\mtype\\
           \typevaljudge\menv{\mexp_3}\mtype}
          {\typevaljudge\menv{\If(\mexp_1,\mexp_2,\mexp_3)}\mtype}
\end{mathpar}

Now we have a typing relation, although it's not exactly clear what we
have gained.  After all, we could have just run a program to discover
if it caused an error.  That said, it still may be cheaper, even for
this simple type system, to compute the type than to compute the
evaluation.  As our language grows, the gap between the resources
required to run and analyze a program can grow without bound, so this
point shouldn't be entirely disregarded.  However, the real value of
this system comes into play after making the following observation:
the environment plays no role in the type relation other than to
signify the types of variables by supplying a witness to the type.
In other words, in the typing derivation of
\[
\typevaljudge{[\mathit{x}\mapsto 4]}{\If(\Eq(\mathit{x},7),\False,\True)}{\Bool}
\]
it doesn't matter at all that $\mathit{x}$ is bound to $4$ in
particular.  Any integer would have sufficed to prove this program
produces a Boolean.  Intuitively, we can make a much stronger claim
about this program, which is that on any integer input, the program
does not produce an error.  By reasoning about a single ``abstract''
run of the program, we can conclude facts about all possible
``concrete'' runs: none of them produce errors.

We can make this claim precise with a relation on environments.
First, let's define:
\begin{align*}
\typeof(\mint) = \Int\\
\typeof(\mbool)= \Bool
\end{align*}
Two environments ``agree,'' written $\menv \sim \menv'$ when they map
variables to values of the same type:
\begin{mathpar}
\inferrule
{\forall \mvar \in \dom(\menv) . \typeof(\menv(\mvar)) = \typeof(\menv'(\mvar))}
{\menv \sim \menv'}
\end{mathpar}

\begin{claim}
If $\typevaljudge\menv\mexp\mtype$ and $\menv \sim \menv'$, then
$\typevaljudge{\menv'}\mexp\mtype$.
\end{claim}
\begin{proof}
By structural induction on the derivation of $\typevaljudge\menv\mexp\mtype$.  The
integer and Boolean cases are trivial.  The variable cases follow from
the definition of $\sim$.  The remaining cases follow by induction.
\end{proof}

Since the environment really only informs the system of the type of
each variable, we can replace the value environment with a
\deftech{type environment} that directly maps a variable to its type.
We use the metavariable $\Gamma$ to range over type environments.  The
type judgment is obtained simply by replacing $\menv$ with $\Gamma$ in
all the rules except the variable rules, which are replaced with:
\begin{mathpar}
\inferrule{\Gamma(\mvar) = \mtype}
          {\typevaljudge\Gamma\mexp\mtype}
\end{mathpar}
%
We can extend the ``$\sim$'' relation to relate type environments and
value environments:
\begin{mathpar}
\inferrule
{\forall \mvar \in \dom(\Gamma) . \Gamma(\mvar) = \typeof(\menv(\mvar)) }
{\Gamma \sim \menv}
\end{mathpar}
The soundness of the typing judgment formalizes our understanding of
the classification of programs into those that do not produce errors
and those that may:
\begin{claim}
If $\typevaljudge\Gamma\mexp\mtype$ and $\Gamma \sim \menv$, then
$\beval\menv\mexp\mval$ and $\typeof(v) = t$.
\end{claim}
\begin{proof}
By structural induction on the derivation of $\typevaljudge\Gamma\mexp\mtype$.
\end{proof}

Type systems are arguably the most effective and widely used formal
verification tool in use today.  In the development above, we've come
up with a fairly simple type system that can prove the absence of
certain errors in programs.  In our case, the class of errors is
simple; it rules out errors arising from branching on non-Booleans and
applying numeric operators to non-numeric arguments.  Much of the work
in developing type systems has been in developing richer notions of
errors and corresponding type judgements that safely classify error
free programs.  But every type system must necessarily throw good
programs out with the bad.  For example, this type system rejects the
following error free programs:
\begin{align*}
\If(\mathit{x},7,\False)\mbox{, where $\mathit{x}:\Bool$}\\
\If(\False,\Eq(\True,1),7)\\
\If(\mathit{x},\If(\mathit{x},7,\Eq(\True,1)),8)\mbox{, where $\mathit{x}:\Bool$}
\end{align*}

\paragraph{Note on Runtime Errors:}
Type systems often only rule out a certain class of errors.  Which
class depends on the particular type system.  The system we've just
developed rules out all errors except $\Err_{\Div0}$ errors, which
were omitted from the presentation for simplicity.  To be precise
about divide-by-zero errors would require some tedious and
uninteresting additions to the semantics and conditions on the claims.


\subsection{Abstract Interpretation with Types}\label{sec:ai-types}

In this section, let's take an alternative perspective on the type
judgement of the previous section.  If ``$:$'' is a funny analog of
``$\Downarrow$'', a natural question is what is the reduction
semantics equivalent of ``$:$''?

First, let's embed types in the language of $\Barith$ expressions:
\[
\begin{array}{llcl}
  & \mexp & ::= & \dots\ |\ \mtype
\end{array}
\]

The reduction axioms are easy to read-off from the typing judgement:
\begin{mathpar}
\inferrule{\ }
          {\envreduce[\Gamma]\mint\treduce\Int}

\inferrule{\ }
          {\envreduce[\Gamma]\mbool\treduce\Bool}

\inferrule{\Gamma(\mvar) = \mtype}
          {\envreduce[\Gamma]{\mvar}\treduce\mtype}

\inferrule{\ }
          {\envreduce[\Gamma]{\Pred(\Int)}\treduce\Int}

\inferrule{\ }
          {\envreduce[\Gamma]{\Succ(\Int)}\treduce\Int}

\inferrule{\ }
          {\envreduce[\Gamma]{\Plus(\Int,\Int)}\treduce\Int}

\inferrule{\ }
          {\envreduce[\Gamma]{\Mult(\Int,\Int)}\treduce\Int}

\inferrule{\ }
          {\envreduce[\Gamma]{\Eq(\Int,\Int)}\treduce\Bool}

\inferrule{\ }
          {\envreduce[\Gamma]{\If(\Bool,\mtype,\mtype)}\treduce\mtype}
\end{mathpar}
We can define $\compat\treduce$ as the compatible closure of
$\treduce$ over the grammar of expressions and $\multicompat\treduce$
as the reflexive, transitive closure of $\compat\treduce$.  Analogs of
the type soundness property hold in this system, too.
\begin{claim}
\label{claim:reduce-soundness}
If $\envreduce[\Gamma]\mexp{\multicompat\treduce}\mtype$ and
$\Gamma\sim\menv$, then
$\envreduce\mexp{\multicompat\breducename}\mval$ and $\typeof(\mval)=\mtype$.
\end{claim}
\begin{exercise}
Prove claim \ref{claim:reduce-soundness}.
\end{exercise}

More than just a change of notation, the reduction semantics view
opens up some new design possibilities.  For example, the $\If$ axiom
requires both branches to be reduced to (abstract) values, i.e.~types,
before proceeding.  What if we mimicked the original semantics more
closely and replace the $\If$ rule with the following:
\begin{mathpar}
\inferrule{\ }
          {\envreduce[\Gamma]{\If(\Bool,\mexp_1,\mexp_2)}{\treduce'}{\mexp_1}}

\inferrule{\ }
          {\envreduce[\Gamma]{\If(\Bool,\mexp_1,\mexp_2)}{\treduce'}{\mexp_2}}
\end{mathpar}

While the above is a more precise abstraction of the $\breducename$
semantics, it leads to some potentially undesirable properties.  The
semantics are not consistent and claim~\ref{claim:reduce-soundness} is
not true.  Consider the example from earlier:
\[
\If(\mathit{x},7,\False)\text{, where }\mathit{x}:\Bool
\]
In the $\treduce'$ semantics, this program reduces to both $\Int$ and
$\Bool$.

\begin{exercise}
Construct a counterexample to claim~\ref{claim:reduce-soundness} for $\treduce'$.
\end{exercise}

The $\multicompat{\treduce'}$ semantics, however, does offer some
strong guarantees.  In particular, the semantics is useful for
informing us of what the program \emph{does not evaluate to}.  If
ruling out behaviors such as type errors is all we care about, this is
just as useful as the previous system which informed of us of what the
program does evaluate to.  After all, saying a program always
evaluates to an integer is a way of saying what it does not evaluate
to, also.

So we can formalize this with the following claim:
\begin{claim}\label{claim:neg-soundness-small}
If $\neg(\envreduce[\Gamma]\mexp{\multicompat{\treduce'}}\mtype)$ and $\Gamma\sim\menv$, then
$\neg(\envreduce\mexp{\multicompat{\breducename}}\mval)$ where $\typeof(\mval)=\mtype$.
\end{claim}
While true, this negative formulation doesn't quite let us conclude
that some programs are error free.  The solution is to again mimick
the original semantics more closely and explicitly characterize the
error behavior of programs.

Suppose we add rules corresponding the axioms for creating and
propagating errors (only showing a small excerpt):
\begin{mathpar}
\inferrule{\mtype \neq \Bool}
          {\envreduce[\Gamma]{\If(\mtype,\mexp_1,\mexp_2)}{\treduce'}{\Err_{\If0}}}

\inferrule{\ }
          {\envreduce[\Gamma]{\If(\merr,\mexp_1,\mexp_2)}{\treduce'}{\merr}}

\inferrule{\ }
          {\envreduce[\Gamma]{\Eq(\merr,\mexp)}{\treduce'}\merr}

\inferrule{\ }
          {\envreduce[\Gamma]{\Eq(\mtype,\merr)}{\treduce'}\merr}
\end{mathpar}
Programs now reduce to a type or an error, which we'll call a type answer:
\[
\begin{array}{llcl}
\mathit{TyAns}  & \mtans & ::= & \mtype\ |\ \merr
\end{array}
\]
We need to relate type answers and answers, which we do by a
relation $\mans \sqsubseteq \mtans$:
\begin{mathpar}
\inferrule{\typeof(\mval) = \mtype}
          {\mval \sqsubseteq \mtype}

\inferrule{\ }
          {\merr \sqsubseteq \merr}
\end{mathpar}
We can now state a generalization of claim~\ref{claim:neg-soundness-small}:
\begin{claim}\label{claim:neg-soundness}
If $\neg(\envreduce[\Gamma]\mexp{\multicompat{\treduce'}}\mtans)$ and $\Gamma\sim\menv$, then
$\neg(\envreduce\mexp{\multicompat{\breducename}}\mans)$ where $\mans \sqsubseteq \mtans$.
\end{claim}
We can also state this claim in an equivalent way which says that if a
program can evaluate to some answer, then an approximation of that
answer is in the abstract evaluation of the program:
\begin{claim}[Soundness]\label{claim:soundness}
If $\envreduce\mexp{\multicompat{\breducename}}\mans$ and
$\Gamma\sim\menv$, then
$\envreduce[\Gamma]\mexp{\multicompat{\treduce'}}\mtans$ where $\mans
\sqsubseteq \mtans$.
\end{claim}
\begin{exercise}
Prove claim~\ref{claim:soundness}.
\end{exercise}

The above formulation lets us talk about error-freedom in a more
refined way since we can say exactly what kind of errors a program may
or may not have.  In fact, it's easy now to deal with divide-by-zero
errors by including reduction axioms for $\Div$:
\begin{mathpar}
\inferrule{\ }
          {\envreduce[\Gamma]{\Div(\Int,\Int)}{\treduce'}{\Int}}

\inferrule{\ }
          {\envreduce[\Gamma]{\Div(\Int,\Int)}{\treduce'}{\Err_{\Div0}}}
\end{mathpar}
The case on the right may seem unfortunate because it says that
\emph{any} program that includes a $\Div$ operation which may be
evaluated can cause a divide-by-zero error, including things like
$\Div(12,4)$.  But that's no different that the guarantee OCaml gives
you when it says an expression is of type {\tt int}.  In the system
above, at least we can say that if an expression does not (abstractly)
reduce to $\Err_{\Div0}$, then it definitely cannot produce a
divide-by-zero error.

The development of the reduction-based formulation of type system is
an instance of \deftech{abstract interpretation}.  And in fact, the
original type judgement can be seen as a further abstract
interpretation of the reduction semantics.  Abstract interpretation
(AI) is a general theory of semantic approximation.  Therefore it
serves as a good foundation for the theory of static analysis since
static analysis consists of computable semantic approximations.  (AI
is also useful beyond static analysis as it can be used to related
different forms of semantics such as natural semantics and reduction
semantics.)

%% The theory of abstract interpretation is grounded in the theory of
%% lattices and Galois connections, which relates two partially ordered
%% sets.  Before studying AI in detail though, let's just develop another
%% example to gain intuitions.


\subsection{Abstract Interpretation with Intervals}\label{sec:ai-intv}

In this section, let's develop another abstract interpretation of
$\Barith$, this time with a more refined abstract domain.  On
integers, we'll use intervals and interpret the integer operations
using interval arithmetic and on Booleans we'll do no approximation.
Intervals will be represented as a pair of extended integers,
i.e. integers extended with ``$\infty$'' and ``$-\infty$''.  We'll use
$\meint$ and $\moeint$ to range over extended integers and $\mintv$
and $\mointv$ to range over intervals, i.e. pairs of extended integers
$(\meint,\moeint)$ where we assume $\meint$ is either $-\infty$ or an
integer and $\moeint$ is either $\infty$ or an integer.  An interval
is interpreted as a non-empty set of integers in the following way:
\begin{align*}
(-\infty,\infty) &= \mathbb{Z}\\
(-\infty,\moint) &= \{ \mint'\ |\ \mint' \leq \moint \}\\
(\mint,\infty) &= \{ \mint'\ |\ \mint \leq \mint' \}\\
(\mint,\moint) &= \{ \mint'\ |\ \mint \leq \mint' \leq \moint \}
\end{align*}

We define the $\BI$ language as $\Barith$, but with intervals in place
of integers in the set of values:
\[
\begin{array}{llcl}
\mathit{Exp}  & \mexp & ::= & \dots\ |\ \mint\ |\ \mintv\\
\mathit{Val}  & \mval & ::= & \mintv\ |\ \mbool
\end{array}
\]

Instead of a type environment as used in $\treduce$, we'll let
$\Gamma$ range over interval environments that map variables to
intervals (or Booleans).
%
The reduction axioms are easy in many cases:
\begin{mathpar}
\inferrule{\ }
          {\envreduce[\Gamma]\mint\ireduce(\mint,\mint)}

\inferrule{\Gamma(\mvar) = \mval}
          {\envreduce[\Gamma]\mvar\ireduce\mval}

\inferrule{\ }
          {\envreduce[\Gamma]{\Pred(\mintv)}\ireduce{\mintv - (1,1)}}

\inferrule{\ }
          {\envreduce[\Gamma]{\Succ(\mintv)}\ireduce{\mintv + (1,1)}}

\inferrule{\ }
          {\envreduce[\Gamma]{\Plus(\mintv,\mointv)}\ireduce{\mintv + \mointv}}

\inferrule{\ }
          {\envreduce[\Gamma]{\Mult(\mintv,\mointv)}\ireduce{\mintv \cdot \mointv}}

\inferrule{\ }
          {\envreduce[\Gamma]{\If(\True,\mexp_1,\mexp_2)}\ireduce{\mexp_1}}

\inferrule{\ }
          {\envreduce[\Gamma]{\If(\False,\mexp_1,\mexp_2)}\ireduce{\mexp_2}}
\end{mathpar}
These definitions make use of extended interval arithmetic operations
``$+$'', ``$-$'', and ``$\cdot$''.  Interval arithmetic is well
understood mathematical domain, and these operations can be
illustrated with just a few examples:
\begin{align*}
(1,5)+(3,9) &= (4,14)\\
(2,5)\cdot(3,9) &= (6,45)\\
(-\infty,5)\cdot(3,9) &= (-\infty,45)
\end{align*}

Things get trickier with equality.  Because an interval represents a
set of potential integer values, $\Eq(\mintv,\mointv)$ must produce
$\True$ whenever there are two equal integers in the sets denoted by
$\mintv$ and $\mointv$ and $\False$ whenever there are two unequal
integers in the sets.
\begin{mathpar}
\inferrule{\exists\mint\in\mintv.\exists\moint\in\mointv.\mint=\moint}
          {\envreduce[\Gamma]{\Eq(\mintv,\mointv)}\ireduce{\True}}

\inferrule{\exists\mint\in\mintv.\exists\moint\in\mointv.\mint\neq\moint}
          {\envreduce[\Gamma]{\Eq(\mintv,\mointv)}\ireduce{\False}}
\end{mathpar}
These definitions give the most precise relation our interval
abstraction allows; i.e. this is the best approximation possible
without changing the domain.  The preconditions form a good
specification, but clearly an implementation should not enumerate the
(potentially infinite) integers in $\mintv$ and $\mointv$ to check the
for (in-)equality.  Instead, produce $\True$ whenever $\mintv$ and
$\mointv$ overlap at all.  Determining when to produce $\False$
requires a little more thought.  You want to produce $\False$ almost
all the time.  When should $\False$ not be one of the results?

Things get even trickier with division.  First, here are some examples
of integer division on intervals:
\begin{align*}
(12,24)\mathop\backslash(3,4) &= (3,8)\\
(12,24)\mathop\backslash(3,\infty) &= (0,8)\\
(12,\infty)\mathop\backslash(3,\infty) &= (0,\infty)
\end{align*}
Interval division is not defined when $0$ is in the denominator
interval.

It's tempting to define $\ireduce$ for $\Div$ as the following:
\begin{mathpar}
\inferrule{0 \not\in \mointv}
          {\envreduce[\Gamma]{\Div(\mintv,\mointv)}\ireduce{\mintv \mathop{\backslash} \mointv}}

\inferrule{0 \in \mointv}
          {\envreduce[\Gamma]{\Div(\mintv,\mointv)}\ireduce{\Err_{\Div0}}}
\end{mathpar}
But this definition is not sound.  To see why, let's formalize the
soundness property.  Again, it will be in terms of a refinement
relation between answers of $\Barith$ and $\BI$:
\begin{mathpar}
\inferrule{\mint \in \mintv}
          {\mint \sqsubseteq \mintv}

\inferrule{\ }
          {\merr \sqsubseteq \merr}

\inferrule{\ }
          {\mbool \sqsubseteq \mbool}
\end{mathpar}
This relation is lifted to environments as usual:
\begin{mathpar}
\inferrule{\forall \mvar \in \dom(\menv) . \menv(\mvar) \sqsubseteq \Gamma(\mvar)}
          {\menv \sqsubseteq \Gamma}
\end{mathpar}
Assuming $\multicompat\ireduce$ is the reflexive transitive closure of
the compatible closure of $\ireduce$, the soundness claim is then:
\begin{claim}[Soundness]\label{claim:intv-soundness}
If $\envreduce\mexp{\multicompat{\breducename}}\mans$ and
$\menv \sqsubseteq \Gamma$, then
$\envreduce[\Gamma]\mexp{\multicompat{\ireduce}}\mans'$ where $\mans
\sqsubseteq \mans'$.
\end{claim}
\begin{exercise}
Construct a counterexample to claim~\ref{claim:intv-soundness} using
the faulty definition of $\ireduce$ for $\Div$.
\end{exercise}

\begin{exercise}
Design the best sound alternative of $\ireduce$ for $\Div$.
By sound, it should validate claim~\ref{claim:intv-soundness};
by best, it should be the smallest relation that does so.
\end{exercise}

\subsection{Refinement Types}

In section~\ref{sec:type-judgments} we developed a simple type system
that ruled out type errors.  By viewing the typing judgement as a
approximate evaluation relation, we explored an equivalent formulation
of the type system as an approximate reduction relation in
section~\ref{sec:ai-types}.  We then revealed a more precise semantics
for proving the absence of type errors.  In section~\ref{sec:ai-intv},
we developed an interval abstraction of the reduction semantics for
$\Barith$.  We can also go in the opposite direction and derive a
further approximation of the interval abstraction in the form of a
natural semantics.  This semantics takes the form of a type judgment,
where the the language of types is refined by an interval in the case
of integers:
\[
\begin{array}{llcl}
\mathit{Type}  & \mtype & ::= & \Bool\ |\ \Int(\mintv)
\end{array}
\]

The type $\Int(\mintv)$ is known as a \deftech{refinement type}, which
is a type qualified by a predicate which holds for every value of that
type.  For our purposes, the predicates only include intervals, but
richer refinement type systems can be defined by embedding richer
logics of predicates into the types.  Refinement types, while not
quite mainstream yet, are featured in several mature research project
such as the refinement type system for F\# called
F7\footnote{\url{http://research.microsoft.com/en-us/projects/f7/}}
and a variant of Haskell with refinements called Liquid
Haskell\footnote{\url{http://goto.ucsd.edu/~rjhala/liquid/haskell/blog/about/}}.

To derive the type system from the reduction semantics, we start with
a straightforward reformulation of most of the axioms:

\begin{mathpar}
\inferrule{\ }
          {\typevaljudge\Gamma\mint{\Int(\mint,\mint)}}

\inferrule{\Gamma(\mvar) = \mtype}
          {\typevaljudge\Gamma\mvar{\mtype}}

\inferrule{\typevaljudge\Gamma\mexp{\Int(\mintv)}}
          {\typevaljudge\Gamma{\Pred(\mexp)}{\Int(\mintv-(1,1))}}

\inferrule{\typevaljudge\Gamma\mexp{\Int(\mintv)}}
          {\typevaljudge\Gamma{\Succ(\mexp)}{\Int(\mintv+(1,1))}}

\inferrule{\typevaljudge\Gamma{\mexp_1}{\Int(\mintv)} \\
           \typevaljudge\Gamma{\mexp_2}{\Int(\mointv)}}
          {\typevaljudge\Gamma{\Plus(\mexp_1,\mexp_2)}{\Int(\mintv+\mointv)}}

\inferrule{\typevaljudge\Gamma{\mexp_1}{\Int(\mintv)} \\
           \typevaljudge\Gamma{\mexp_2}{\Int(\mointv)}}
          {\typevaljudge\Gamma{\Mult(\mexp_1,\mexp_2)}{\Int(\mintv\cdot\mointv)}}

\inferrule{\typevaljudge\Gamma{\mexp_1}{\Int(\mintv)} \\
           \typevaljudge\Gamma{\mexp_2}{\Int(\mointv)}}
          {\typevaljudge\Gamma{\Eq(\mexp_1,\mexp_2)}{\Bool}}

\inferrule{\typevaljudge\Gamma{\mexp_1}{\Bool} \\
           \typevaljudge\Gamma{\mexp_2}{\mtype_2} \\
           \typevaljudge\Gamma{\mexp_3}{\mtype_3} \\
           \mtype = \mtype_2 \sqcup \mtype_3}
          {\typevaljudge\Gamma{\If(\mexp_1,\mexp_2,\mexp_3)}{\mtype}}
\end{mathpar}
The rule for $\If$ joins the type of its branches with the $\sqcup$
function, which is defined as:
\begin{mathpar}
\inferrule{\ }
          {\Bool \sqcup \Bool = \Bool}

\inferrule{\meint = \min(\meint_1,\meint_2) \\ \moeint = \max(\moeint_1,\moeint_2) }
          {(\meint_1,\moeint_1) \sqcup (\meint_2,\moeint_2) = (\meint,\moeint)}
\end{mathpar}
The rule for $\Div$ can be quite conservative and require that $0$ not
be in the denominator.  This rules out many programs, but is sound.
If we require the typing judgment to be a function, it is the only
option we have:
\begin{mathpar}
\inferrule{\typevaljudge\Gamma{\mexp_1}{\Int(\mintv)} \\
           \typevaljudge\Gamma{\mexp_2}{\Int(\mointv)} \\
           0 \not\in \mointv}
          {\typevaljudge\Gamma{\Div(\mexp_1,\mexp_2)}{\Int(\mintv\intvdiv\mointv)}}
\end{mathpar}


\begin{claim}
  If $\typevaljudge\Gamma\mexp\mtype$ and $\menv \sqsubseteq \Gamma$, then
  $\beval\menv\mexp\mval$ and $\mval \sqsubseteq \mtype$.
\end{claim}
This claim relies on the following definition of $\sqsubseteq$:
\begin{mathpar}
\inferrule{\ }
          {\mbool \sqsubseteq \Bool}

\inferrule{\mint \in \mintv}
          {\mint \sqsubseteq \Int(\mintv)}

\inferrule{\forall \mvar \in \dom(\menv).\menv(\mvar) \sqsubseteq \Gamma(\mvar) }
          {\menv \sqsubseteq \Gamma}

\end{mathpar}

\begin{exercise}
Interval refinements as defined above are a course-grained
approximation because an interval is given by a single pair of
extended integers; this abstraction cannot express, for example, that
an integer $\mint$ is approximated by a set such as $(-5 \leq \mint
\leq -2) \vee (2 \leq \mint \leq 5)$.  However interval arithmetic is
perfectly capable of operating on finite unions of intervals.  Design
a refinement type system that refines integers by sets of intervals.
It should prove the safety of the following program:
\[
[\mvar\mapsto \Int\{(-5,-2),(2,5)\}] \vdash \Div(5,\mvar):\Int\{(-2,-1),(1,2)\}
\]
\end{exercise}

\subsection{Symbolic Execution}

Symbolic execution is another approach to reasoning about all possible
executions of program that is achieved by considering inputs to a
program symbolically.  In other words, if a program takes as input an
integer \(\mathit{x}\), we will run the program using ``\(\mathit{x}\)''
as a placeholder for any possible integer.  This is not unlike how we
reason mathematically.  If you see the function
\[
f(x) = x \cdot 0\text,
\]
this is equivalent to \(f(x) = 0\); there's no need to wait until the
function is applied to a particular input to come to this conclusion.

Similarly, if we have the following program:
\[
\If(\Eq(\Plus(\mathit{x},\mathit{x}), \Mult(2,\mathit{x})), 3, 4)\text,
\]
it's easy to see it can never reduce to 4, no matter what value
\(\mathit{x}\) takes on.

Symbolic reasoning often involves reasoning by implication.  For
example, consider a slight tweak to the above program:
\[
\If(\Eq(\mathit{x},\mathit{y}),
 \If(\Eq(\Plus(\mathit{x},\mathit{x}), \Mult(2,\mathit{y})), 3, 4),
  8)\text.
\]
This program also cannot reduce to 4, no matter what values
\(\mathit{x}\) or \(\mathit{y}\) take on.  The reasoning is obvious:
if \(\mathit{x}\) is not equal to \(\mathit{y}\), the \(\If\) takes the
alternative branch and the result is 8.  If \(\mathit{x}\) is equal to
\(\mathit{y}\), the \(\If\) takes the consequent branch, which is just the
example from before, but with an \(\mathit{x}\) replaced with a
\(\mathit{y}\).  But we've already assumed \(\mathit{x}\) equals
\(\mathit{y}\), so of course the same facts should hold as before.

We call the logical assertion \(\Eq(\mathit{x}, \mathit{y})\) a
\deftech{path condition} on the execution of the consequent branch.
Likewise, there is a (unneeded) path condition on the alternative,
which asserts \(\neg\Eq(\mathit{x},\mathit{y})\).

The idea behind symbolic execution is to augment our reduction
semantics to deal with symbolic data, namely variables, and to build
up facts about the program as a logical statement about what must be
true at any given point during the execution.  The form of the logical
statement is a conjunction of conditions which must hold at that point
in the execution.  If an inconsistent set of facts are ever reached,
we can conclude that state of execution is infeasible and cannot
actually be reached.
\[
\begin{array}{llcl}
\mathit{Symbolic\ value}  & \msval & ::= & \mvar\ |\ \mval\\
\mathit{Path\ condition}  & \mpath & ::= & \{ \mcon, \dots \}\\
\mathit{Condition}        & \mcon  & ::= & \mvar\ |\ \neg\mcon\ |\ \Eq(\mvar,\Pred(\mvar))\ |\ \Eq(\mvar,\Succ(\mvar))\\
                          &        & |\  & \Eq(\mvar,\Mult(\msval,\msval))\ |\ \Eq(\mvar,\Div(\msval,\msval))\ |\ \Eq(\msval,\msval)
\end{array}
\]

The reduction of an expression is formulated as a reduction relation
on expression and path condition pairs:
$\envreduce[\relax]{(\mexp,\mpath)}\sreduce{(\mexp',\mpath')}$.  The
meaning of such a reduction is that $\mexp$, under the assumptions of
$\mpath$, may reduce to to $\mexp'$, implying conditions $\mpath'$.

We use a relation on path conditions $\allows\mcon$, which denotes
that $\mpath$ ``allows'' $\mcon$ to be true; in other words
$\mpath\cup\{\mcon\}$ is not a contradiction.  You can think of the
$\allows\mcon$ judgement as being an embedded model checker in our
language.  We can produce a tighter characterization of a program's
behavior (i.e.~produce a smaller reduction graph) if we use a powerful
model checker, but so long as the model checker is sound, the
semantics will be sound.  The simplest sound model checker is just the
one that allows everything:
\begin{mathpar}
\inferrule{\ }
          {\allows\mcon}
\end{mathpar}
A slightly more refined one is the following:
\begin{mathpar}
\inferrule{\neg\mcon \not\in \mpath}
          {\allows\mcon}

\inferrule{\mcon \not\in \mpath}
          {\allows\neg\mcon}

\inferrule{\mvar:\Bool \not\in \mpath}
          {\allows{\mvar:\Int}}

\inferrule{\mvar:\Int \not\in \mpath}
          {\allows{\mvar:\Bool}}
\end{mathpar}
In general what we want is:
\begin{mathpar}
\inferrule{\mpath \cup \{\mcon\} \mbox{ is satisfiable }}
          {\allows\mcon}
\end{mathpar}
In our case, the logical formulas are expressed in first-order logic
with equality, using a theory of integer arithmetic.  Such
satisfiability problems are ubiquitous in computer science. The
\deftech{Satisfiability Modulo Theories} (SMT) problem is a decision
problem for logical formulas with background theories expressed in
first-order logic with equality.  You've probably heard of the Boolean
satisfiability problem (SAT), which is just an instance of the SMT
problem, using Boolean arithmetic as the underlying theory.  Other
theories might include the theories of real numbers, intervals, data
structures, and so on.  There are many mature SMT solvers available
(e.g.~Z3, CVC4), which can effectively decide $\allows\mcon$.  If we
had a richer language, the path conditions would involve richer
theories, which may not be decidable.  At that point, a sound
approximation would need to be used.

Let's now look at some of the reduction rules:
\begin{mathpar}
\inferrule{\allows{\mvar}}
          {\envreduce[\relax]{\If(\mvar,\mexp_1,\mexp_2), \mpath}\sreduce{\mexp_1}, \mpath \cup \{ \mvar\} }

\inferrule{\allows{\neg\mvar}}
          {\envreduce[\relax]{\If(\mvar,\mexp_1,\mexp_2), \mpath}\sreduce{\mexp_2}, \mpath \cup \{ \neg\mvar\} }
\end{mathpar}
Here, an $\If$ takes the consequent branch whenever the test variable
may be true (determined by using $\allows\mvar$) and adds $\mvar$ to
the path condition.  Symmetrically, $\If$ takes the alternative
whenever the test may be false and adds $\neg\mvar$ to the path
condition.

You may wonder why $\mvar$ is added to $\mpath$ if $\allows\mvar$
already holds.  The answer is that $\allows\mvar$ only determines if
it is possible that $\mvar$ is true.  When $\mvar$ is added to the
path condition, we are asserting that $\mvar$ \emph{is} true.
Consider this example:
\[
\If(\mathit{x}, \If(\mathit{x}, 1, 2), 3)
\]
This program can produce either 1 or 3 because $\mathit{x}$ may be
either true or false, but it cannot produce 2 because that would
require $\mathit{x}$ to be true in the first conditional and false in
the second.  This is reflected in the reduction semantics because
$\allows[\emptyset]{\mathit{x}}$ and
$\allows[\emptyset]{\neg\mathit{x}}$ in the first conditional.  But
when the consequent branch is taken, we add $\mathit{x}$ to the path
condition, which rules out producing 2 since it's not the case that
$\allows[\{\mathit{x}\}]{\neg\mathit{x}}$.

Here are some rules for arithmetic operations:
\begin{mathpar}
\inferrule{\ }
          {\envreduce[\relax]{\Pred(\mvar),\mpath}\sreduce{\mvar',\mpath\cup\{\Eq(\mvar',\Pred(\mvar))\}}}

\inferrule{\ }
          {\envreduce[\relax]{\Succ(\mvar),\mpath}\sreduce{\mvar',\mpath\cup\{\Eq(\mvar',\Succ(\mvar))\}}}

\inferrule{\ }
          {\envreduce[\relax]{\Plus(\msval_1,\msval_2),\mpath}\sreduce{\mvar',\mpath\cup\{\Eq(\mvar',\Plus(\msval_1,\msval_2))\}}}

\inferrule{\ }
          {\envreduce[\relax]{\Mult(\msval_1,\msval_2),\mpath}\sreduce{\mvar',\mpath\cup\{\Eq(\mvar',\Mult(\msval_1,\msval_2))\}}}
\end{mathpar}
In each of these rules, the variable $\mvar'$ is introduced by
reduction.  These variables are understood to be ``fresh'', i.e.~they
are variables that have not been used before.

The $\Div$ rule is more interesting since we have pre- and
post-conditions on the denominator:
\begin{mathpar}
\inferrule{\allows{\neg\Eq(0,\msval_2)} }
          {\envreduce[\relax]{\Div(\msval_1,\msval_2),\mpath}\sreduce{\mvar',\mpath\cup\{\Eq(\mvar',\Div(\msval_1,\msval_2)), \neg\Eq(0,\msval_2)\}}}

\inferrule{\allows{\Eq(0,\msval_2)} }
          {\envreduce[\relax]{\Div(\msval_1,\msval_2),\mpath}\sreduce{\Err_{\Div0}, \mpath\cup\{\Eq(0,\msval_2)\}}}
\end{mathpar}
Finally, we have the rule for $\Eq$:
\begin{mathpar}
\inferrule{\allows{\Eq(\msval_1,\msval_2)}}
          {\envreduce[\relax]{\Eq(\msval_1,\msval_2),\mpath}\sreduce{\True, \mpath\cup\{\Eq(\msval_1,\msval_2)\}}}

\inferrule{\allows{\neg\Eq(\msval_1,\msval_2)}}
          {\envreduce[\relax]{\Eq(\msval_1,\msval_2),\mpath}\sreduce{\False, \mpath\cup\{\neg\Eq(\msval_1,\msval_2)\}}}
\end{mathpar}



\subsection{Type Inference}


Type inference is the process of searching for a proof of the type
correctness of a program.  In terms of the $\Barith$ language, we can
think of it as the problem of determining for an expression $\mexp$ if
there is a type environment $\Gamma$ and type $\mtype$ that exist,
such that $\typevaljudge\Gamma\mexp\mtype$.

Type inference is a common feature of some typed programming
languages.  For example, OCaml is able to infer the types of programs
which make no mention of types in their source text:
\begin{verbatim}
# let rec fact n =
    if (n = 0)
    then 1
    else n * fact (n-1);;
val fact : int -> int = <fun>
\end{verbatim}
Here, OCaml is telling us that it successfully found a proof that the
program is well-typed, and moreover has the type {\tt int -> int},
i.e.~it consumes and produces integers.  It is able to do this without
any explicit mention of types in the program.

The process of type inference is not unlike the process a programmer
might use to discover the type of this program.  Imagine we start
knowing nothing about {\tt fact}.  We can see from the shape of it's
definition that it is a function, so we must determine it's input type
and output type.  Looking at the body of the function, we see {\tt n}
is compared to {\tt 0}.  This constrains {\tt n} to be a integer,
since {\tt n} is a argument to the integer equality operation.  Later,
{\tt n} is an argument to both subtraction and multiplication
operations, which also implies {\tt n} must be an integer.  To
determine the output type of the function, we can see that {\tt fact}
produces {\tt 1} in one branch of the conditional.  Thus it could
produce an integer.  In the other branch, it produces the result of
multiplication, which also implies the output type is integer.
Finally the fact that {\tt fact} is the argument to a multiplication
operation also suggests it needs to produce an integer.

In this informal analysis what we've done is collect a set of
constraints on the usage of variables.  If that set of constraints is
consistent, i.e. a variable is not used as an integer in one place and
as a Boolean in another, then we conclude the program is type correct.
This informal process can be made rigorous to produce a type inference
algorithm.  The idea will be to generate a set of type
constraints---equations between types and variables---and then try to
solve the system of equations.  If the equations have a solution, the
program is type correct.  If they don't, we can conclude the program
is ill-typed.


In this setting, a type constraint is an equation between types
$\mtype = \mtype'$, but which may contain variables (we'll call a type
with no variables in it a ground type).  A constraint set $\mcset$ is
a set of type constraints.
\[
\begin{array}{llcl}
\mathit{Types}              & \mtype  & ::= & \Int\ |\ \Bool\ |\ \mvar\\
\mathit{Type\ contraints}   & \mcset  & ::= & \{\mtype = \mtype', \dots\}
\end{array}
\]
The way that type constraints are generated is by a type constraint
judgement that produces a type (or variable) and a set of constraints.
The judgement $\typevaljudge\relax\mexp{\mtype,\mcset}$ is defined for
all expressions.  This is unlike the type judgement from
section~\ref{sec:type-judgments}, which was only defined for ``good''
programs.  Instead the type constraint judgement will produce a set of
constraints for any program, but ill-typed programs generate
inconsistent constraint sets.

Here is the inference rule for $\Pred$:
\begin{mathpar}
\inferrule{\typevaljudge\relax\mexp{\mtype,\mcset}}
          {\typevaljudge\relax{\Pred(\mexp)}{\Int,\mcset \cup \{ \mtype = \Int \}}}
\end{mathpar}
Compare this with the type judgement for $\Pred$ from section~\ref{sec:type-judgments}:
\begin{mathpar}
\inferrule{\typevaljudge\Gamma\mexp\Int}
          {\typevaljudge\Gamma{\Pred(\mexp)}{\Int}}
\end{mathpar}
The key difference is that rather than place any restrictions on the
precondition of the rule, in this case that $\mexp$ has type $\Int$,
the constraint version expresses this by adding $\mtype = \Int$ to the
set of constraints.  In order for $\Pred(\mexp)$ to be well-typed,
these constraints must have a solution, which means the type of
$\mexp$ will be $\Int$.

Many other cases are straightforward following this blueprint.  In
each case, we place no conditions in the premise of a rule, but
instead move them to the set of constraints that must be satisfied.
Here is the rule for $\Mult$, for example:
\begin{mathpar}
\inferrule{\typevaljudge\relax{\mexp_1}{\mtype_1,\mcset_1} \\
           \typevaljudge\relax{\mexp_2}{\mtype_2,\mcset_2}}
          {\typevaljudge\relax{\Mult(\mexp_1,\mexp_2)}{\Int,\mcset_1 \cup \mcset_2 \cup \{ \mtype_1 = \Int, \mtype_2 = \Int \}}}
\end{mathpar}

The remaining interesting rules are for variables and conditionals:
\begin{mathpar}
\inferrule{\ }
          {\typevaljudge\relax\mvar{\mvar,\emptyset}}

\inferrule{\typevaljudge\relax{\mexp_i}{\mtype_i,\mcset_i} \\ i \in \{1,2,3\}}
          {\typevaljudge\relax{\If(\mexp_1,\mexp_2,\mexp_3)}{\mtype_2,\bigcup_{i\in\{1,2,3\}} \mcset_i \cup \{ \mtype_1 = \Bool, \mtype_2 = \mtype_3\}}}
\end{mathpar}
A variable generates no constraints, because a variable occurrence
alone doesn't imply anything about how the value of the variable is
used.  But the type of a variable is just the variable's name.  So if
the variable occurs in some context that constrains its type, a type
constraint will be generated for the variable.  For example,
$\Pred(\mvar)$ generates the constraint $\mvar = \Int$.  If a variable
occurs in multiple contexts that use the variable with different types
will generate an inconsistent set of constraints.  For example,
$\If(\mvar,\Succ(\mvar),8)$ will generate the unsolvable equations
$\{\mvar = \Bool, \mvar = \Int\}$.

An $\If$ expression generates type constraints for all its
subexpressions and then constrains the type of the test expression to
be a Boolean and the types of the consequent and alternative to be
equal.  Since they are constrained to be equal, we could have used
$\mtype_1$ instead of $\mtype_2$ as the result type and it wouldn't
make a difference.

Once a constraint set is generated, there is the issue of finding out
if the constraints have a solution.

\newcommand\unify{\mathit{U}}
\newcommand\solve{\mathit{unify}}
\newcommand\msubst{\psi}


The general problem of determining if a set of equations between terms
has a solution is known as the \deftech{unification problem}.
%
The way we will represent a solution to an instance of the unification
problem is as a substitution that unifies all of the equations.  A
substitution is partial function from variables to types.  So if given
a set of constraints $\mcset$, we will try to construct a substitution
$\msubst$ such that $\msubst(\mcset)$ produces a set of trivial
equations: $\msubst(\mcset) = \{\mtype_1 = \mtype_1, \mtype_2 =
\mtype_2, \dots\}$.




The unification of a set of equations is given by the following
function, $\solve(\mcset)$:
\begin{gather*}
\solve(\mcset) = \unify(\mcset,\emptyset)\mbox{ where } \\
\begin{align}
\unify(\emptyset,\msubst) &= \msubst\\
\unify(\{\mtype = \mtype\}\cup\mcset,\msubst) &= \unify(\mcset,\msubst)\\
\unify(\{\mvar  = \mtype\}\cup\mcset,\msubst) &=
\begin{cases}
\unify(\mcset,\msubst[\mtype/\mvar] \circ [\mvar \mapsto \mtype]) & \mbox{if }\msubst(\mvar) = \bot\\
\unify(\mcset \cup \{ \mtype=\mtype' \},\msubst) & \mbox{if }\msubst(\mvar) = \mtype'\\
\end{cases}\\
\unify(\{\mtype = \mvar\}\cup\mcset,\msubst) &=
\unify(\{\mvar  = \mtype\}\cup\mcset,\msubst)
\end{align}
\end{gather*}

The algorithm works by iteratively removing constraints, building a
substitution, until there are no constraints left.  If a constraint is
trivial, i.e.~it is of the form $\mtype = \mtype$, then it is removed.
If a constraint is between a variable and a type, and the variable is
not already in the solution, then the type replaces the variable in
the substitution (denoted $\msubst[\mtype/\mvar]$) and the mapping
from the variable to the type is added to the solution.  If the
variable is already in the substitution, a new constraint is added to
equate the type and what's given by the substitution.

The unification is sound and complete: it produces a substitution
whenever one exists, and the substitution produced is always a
solution.  If a solution exists, the program is well-typed under some
typing environment:
\begin{claim}
If $\typevaljudge\relax\mexp{\mtype,\mcset}$ and $\solve(\mcset) =
\msubst$, then there exists $\Gamma$ and $\mtype'$ such that
$\typevaljudge\Gamma\mexp{\mtype'}$.
\end{claim}

The typing environment is \emph{almost} the same as the substitution
$\msubst$, but we have to be a little careful about underconstrained
variables.  For example in this program:
$\If(\True,\mathit{x},\mathit{y})$, the variables $\mathit{x}$ and
$\mathit{y}$ must have the same type, which also the type of the whole
program, but the solution to the constraints generated by this program
is either $[\mathit{x}\mapsto\mathit{y}]$ or vice versa, which is not
a type environment.

%% If $\mint \in \mintv$, $\moint \in \mointv$, and $\mint' = \mint
%% \intvdiv \moint$ then ${\Div(\mintv,\moint)}\mathop{\ireduce}{\mintv'}$ where
%% $\mint' \in \mintv'$.


%% In an abstract interpretation, we have two kinds of values: concrete
%% values, which are drawn from the semantics of our programming
%% language, and abstract values, which are drawn from the particular
%% domain which we choose to approximate programs.  In the previous
%% section, concrete values consisted of integers, Booleans, and errors;
%% abstract values consisted of types and errors.

%% \begin{align*}
%% \alpha(A) &= \bigcup_{\mans\in A} \{ \alpha_{\Ans}(\mans) \}\text{, where}\\
%% \alpha_\mans(\mint) &= \Int\\
%% \alpha_\mans(\mbool) &= \Bool\\
%% \alpha_\mans(\merr) &= \merr
%% \end{align*}

%% \begin{align*}
%% \gamma(T) &= \bigcup_{\mtans \in T} x
%% \end{align*}




%% \subsection{Programs Gone Wrong}

%% A type error is any error that arises from the program using the wrong
%% kind of value than required by the language, such as in
%% $\Mult(\False,4)$.  To be precise, the set of type errors for
%% $\Barith$ are:
%% \[
%% \mathit{TypeError} = \{ \Err_\ell\ |\
%% \ell \in \{ \If, \Pred, \Succ, \Eq1, \Eq2, \Div1, \Div2, \Mult1, \Mult2, \Plus1, \Plus2 \} \cup \mathit{Var}\}
%% \]


%% Let's formally define the property of programs:

%% \begin{align*}
%% P(\menv,\mexp) \iff \menv \vdash \mexp =_\breducename \merr \text{, where } \merr \in \mathit{TypeError}\\
%% Q(\mexp) \iff \exists \menv. \menv\text{ closes } \mexp\text{ and } \vdash \mexp =_\breducename \merr \text{, where } \merr \in \mathit{TypeError}
%% \end{align*}
